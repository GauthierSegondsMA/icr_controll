{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import requests\n",
    "import boto3 # module pour se connecter au serveur S3\n",
    "from botocore.client import Config # module pour se connecter au serveur S3\n",
    "import logging # module pour se connecter au serveur S3\n",
    "from botocore.exceptions import ClientError # module pour se connecter au serveur S3\n",
    "import pandas as pd # module pour créer des dataframes\n",
    "import numpy as np # module pour gérer les arrays\n",
    "from jsonpath_ng import jsonpath, parse # module python pour faire des requête dans un JSON\n",
    "from openpyxl import workbook #module pour travailler avec excels et des dataframes\n",
    "from openpyxl import load_workbook  #module pour travailler avec excels et des dataframes\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows #module pour travailler avec excels et des dataframes\n",
    "from openpyxl import Workbook #module pour travailler avec excels et des dataframes\n",
    "import openpyxl as xl # module pour gérer les classeurs excels\n",
    "import io  # module pour gérer flux de données (écrire un JSON)\n",
    "import sys\n",
    "import img2pdf, time # module pour transformer tiff en pdf\n",
    "from PIL import Image\n",
    "import traceback\n",
    "from nltk import edit_distance\n",
    "from tenacity import *\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des classes et fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Any, List, Union, TypeVar, Callable, Type, cast\n",
    "from datetime import datetime\n",
    "import dateutil.parser\n",
    "import json\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "\n",
    "def from_str(x: Any) -> str:\n",
    "    assert isinstance(x, str)\n",
    "    return x\n",
    "\n",
    "\n",
    "def from_int(x: Any) -> int:\n",
    "    assert isinstance(x, int) and not isinstance(x, bool)\n",
    "    return x\n",
    "\n",
    "\n",
    "def from_none(x: Any) -> Any:\n",
    "    assert x is None\n",
    "    return x\n",
    "\n",
    "\n",
    "def from_union(fs, x):\n",
    "    for f in fs:\n",
    "        try:\n",
    "            return f(x)\n",
    "        except:\n",
    "            pass\n",
    "    assert False\n",
    "\n",
    "\n",
    "def from_float(x: Any) -> float:\n",
    "    assert isinstance(x, (float, int)) and not isinstance(x, bool)\n",
    "    return float(x)\n",
    "\n",
    "\n",
    "def from_list(f: Callable[[Any], T], x: Any) -> List[T]:\n",
    "    assert isinstance(x, list)\n",
    "    return [f(y) for y in x]\n",
    "\n",
    "\n",
    "def to_float(x: Any) -> float:\n",
    "    assert isinstance(x, float)\n",
    "    return x\n",
    "\n",
    "\n",
    "def to_class(c: Type[T], x: Any) -> dict:\n",
    "    assert isinstance(x, c)\n",
    "    return cast(Any, x).to_dict()\n",
    "\n",
    "\n",
    "def from_bool(x: Any) -> bool:\n",
    "    assert isinstance(x, bool)\n",
    "    return x\n",
    "\n",
    "\n",
    "def from_datetime(x: Any) -> datetime:\n",
    "    return dateutil.parser.parse(x)\n",
    "\n",
    "\n",
    "class AggCat:\n",
    "    cat: str\n",
    "    reference_price: Optional[int]\n",
    "    score: str\n",
    "\n",
    "    def __init__(self, cat: str, reference_price: Optional[int], score: str) -> None:\n",
    "        self.cat = cat\n",
    "        self.reference_price = reference_price\n",
    "        self.score = score\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(obj: Any) -> 'AggCat':\n",
    "        assert isinstance(obj, dict)\n",
    "        cat = from_str(obj.get(\"cat\"))\n",
    "        reference_price = from_union([from_int, from_none], obj.get(\"reference_price\"))\n",
    "        score = from_str(obj.get(\"score\"))\n",
    "        return AggCat(cat, reference_price, score)\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        result: dict = {}\n",
    "        result[\"cat\"] = from_str(self.cat)\n",
    "        result[\"reference_price\"] = from_union([from_int, from_none], self.reference_price)\n",
    "        result[\"score\"] = from_str(self.score)\n",
    "        return result\n",
    "\n",
    "\n",
    "class Category:\n",
    "    cat: str\n",
    "    score: str\n",
    "\n",
    "    def __init__(self, cat: str, score: str) -> None:\n",
    "        self.cat = cat\n",
    "        self.score = score\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(obj: Any) -> 'Category':\n",
    "        assert isinstance(obj, dict)\n",
    "        cat = from_str(obj.get(\"cat\"))\n",
    "        score = from_str(obj.get(\"score\"))\n",
    "        return Category(cat, score)\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        result: dict = {}\n",
    "        result[\"cat\"] = from_str(self.cat)\n",
    "        result[\"score\"] = from_str(self.score)\n",
    "        return result\n",
    "\n",
    "\n",
    "class Quantite:\n",
    "    content: str\n",
    "    coordinates: str\n",
    "    score: str\n",
    "\n",
    "    def __init__(self, content: str, coordinates: str, score: str) -> None:\n",
    "        self.content = content\n",
    "        self.coordinates = coordinates\n",
    "        self.score = score\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(obj: Any) -> 'Quantite':\n",
    "        assert isinstance(obj, dict)\n",
    "        content = from_str(obj.get(\"content\"))\n",
    "        coordinates = from_str(obj.get(\"coordinates\"))\n",
    "        score = from_str(obj.get(\"score\"))\n",
    "        return Quantite(content, coordinates, score)\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        result: dict = {}\n",
    "        result[\"content\"] = from_str(self.content)\n",
    "        result[\"coordinates\"] = from_str(self.coordinates)\n",
    "        result[\"score\"] = from_str(self.score)\n",
    "        return result\n",
    "\n",
    "\n",
    "class Record:\n",
    "    h_x0: float\n",
    "    h_x1: float\n",
    "    h_y0: float\n",
    "    h_y1: float\n",
    "    agg_cat: List[AggCat]\n",
    "    categories: List[Category]\n",
    "    n_agg_cat: int\n",
    "    n_categories_baremo: int\n",
    "    quantite: Quantite\n",
    "    text: Quantite\n",
    "    text_quantite: Quantite\n",
    "    text_units: Quantite\n",
    "    total_prix: Quantite\n",
    "    unit_prix: Quantite\n",
    "    unit_prix_text: Quantite\n",
    "    units: Quantite\n",
    "\n",
    "    def __init__(self, h_x0: float, h_x1: float, h_y0: float, h_y1: float, agg_cat: List[AggCat], categories: List[Category], n_agg_cat: int, n_categories_baremo: int, quantite: Quantite, text: Quantite, text_quantite: Quantite, text_units: Quantite, total_prix: Quantite, unit_prix: Quantite, unit_prix_text: Quantite, units: Quantite) -> None:\n",
    "        self.h_x0 = h_x0\n",
    "        self.h_x1 = h_x1\n",
    "        self.h_y0 = h_y0\n",
    "        self.h_y1 = h_y1\n",
    "        self.agg_cat = agg_cat\n",
    "        self.categories = categories\n",
    "        self.n_agg_cat = n_agg_cat\n",
    "        self.n_categories_baremo = n_categories_baremo\n",
    "        self.quantite = quantite\n",
    "        self.text = text\n",
    "        self.text_quantite = text_quantite\n",
    "        self.text_units = text_units\n",
    "        self.total_prix = total_prix\n",
    "        self.unit_prix = unit_prix\n",
    "        self.unit_prix_text = unit_prix_text\n",
    "        self.units = units\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(obj: Any) -> 'Record':\n",
    "        assert isinstance(obj, dict)\n",
    "        h_x0 = from_float(obj.get(\"H_X0\"))\n",
    "        h_x1 = from_float(obj.get(\"H_X1\"))\n",
    "        h_y0 = from_float(obj.get(\"H_Y0\"))\n",
    "        h_y1 = from_float(obj.get(\"H_Y1\"))\n",
    "        agg_cat = from_list(AggCat.from_dict, obj.get(\"agg_cat\"))\n",
    "        categories = from_list(Category.from_dict, obj.get(\"categories\"))\n",
    "        n_agg_cat = from_int(obj.get(\"n_agg_cat\"))\n",
    "        n_categories_baremo = from_int(obj.get(\"n_categories_baremo\"))\n",
    "        quantite = Quantite.from_dict(obj.get(\"quantite\"))\n",
    "        text = Quantite.from_dict(obj.get(\"text\"))\n",
    "        text_quantite = Quantite.from_dict(obj.get(\"text_quantite\"))\n",
    "        text_units = Quantite.from_dict(obj.get(\"text_units\"))\n",
    "        total_prix = Quantite.from_dict(obj.get(\"total_prix\"))\n",
    "        unit_prix = Quantite.from_dict(obj.get(\"unit_prix\"))\n",
    "        unit_prix_text = Quantite.from_dict(obj.get(\"unit_prix_text\"))\n",
    "        units = Quantite.from_dict(obj.get(\"units\"))\n",
    "        return Record(h_x0, h_x1, h_y0, h_y1, agg_cat, categories, n_agg_cat, n_categories_baremo, quantite, text, text_quantite, text_units, total_prix, unit_prix, unit_prix_text, units)\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        result: dict = {}\n",
    "        result[\"H_X0\"] = to_float(self.h_x0)\n",
    "        result[\"H_X1\"] = to_float(self.h_x1)\n",
    "        result[\"H_Y0\"] = to_float(self.h_y0)\n",
    "        result[\"H_Y1\"] = to_float(self.h_y1)\n",
    "        result[\"agg_cat\"] = from_list(lambda x: to_class(AggCat, x), self.agg_cat)\n",
    "        result[\"categories\"] = from_list(lambda x: to_class(Category, x), self.categories)\n",
    "        result[\"n_agg_cat\"] = from_int(self.n_agg_cat)\n",
    "        result[\"n_categories_baremo\"] = from_int(self.n_categories_baremo)\n",
    "        result[\"quantite\"] = to_class(Quantite, self.quantite)\n",
    "        result[\"text\"] = to_class(Quantite, self.text)\n",
    "        result[\"text_quantite\"] = to_class(Quantite, self.text_quantite)\n",
    "        result[\"text_units\"] = to_class(Quantite, self.text_units)\n",
    "        result[\"total_prix\"] = to_class(Quantite, self.total_prix)\n",
    "        result[\"unit_prix\"] = to_class(Quantite, self.unit_prix)\n",
    "        result[\"unit_prix_text\"] = to_class(Quantite, self.unit_prix_text)\n",
    "        result[\"units\"] = to_class(Quantite, self.units)\n",
    "        return result\n",
    "\n",
    "\n",
    "class ContentClass:\n",
    "    n_records: int\n",
    "    records: List[Record]\n",
    "\n",
    "    def __init__(self, n_records: int, records: List[Record]) -> None:\n",
    "        self.n_records = n_records\n",
    "        self.records = records\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(obj: Any) -> 'ContentClass':\n",
    "        assert isinstance(obj, dict)\n",
    "        n_records = from_int(obj.get(\"n_records\"))\n",
    "        records = from_list(Record.from_dict, obj.get(\"records\"))\n",
    "        return ContentClass(n_records, records)\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        result: dict = {}\n",
    "        result[\"n_records\"] = from_int(self.n_records)\n",
    "        result[\"records\"] = from_list(lambda x: to_class(Record, x), self.records)\n",
    "        return result\n",
    "\n",
    "\n",
    "class Position:\n",
    "    xmax: str\n",
    "    xmin: str\n",
    "    ymax: str\n",
    "    ymin: str\n",
    "\n",
    "    def __init__(self, xmax: str, xmin: str, ymax: str, ymin: str) -> None:\n",
    "        self.xmax = xmax\n",
    "        self.xmin = xmin\n",
    "        self.ymax = ymax\n",
    "        self.ymin = ymin\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(obj: Any) -> 'Position':\n",
    "        assert isinstance(obj, dict)\n",
    "        xmax = from_str(obj.get(\"xmax\"))\n",
    "        xmin = from_str(obj.get(\"xmin\"))\n",
    "        ymax = from_str(obj.get(\"ymax\"))\n",
    "        ymin = from_str(obj.get(\"ymin\"))\n",
    "        return Position(xmax, xmin, ymax, ymin)\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        result: dict = {}\n",
    "        result[\"xmax\"] = from_str(self.xmax)\n",
    "        result[\"xmin\"] = from_str(self.xmin)\n",
    "        result[\"ymax\"] = from_str(self.ymax)\n",
    "        result[\"ymin\"] = from_str(self.ymin)\n",
    "        return result\n",
    "\n",
    "\n",
    "class Bbox:\n",
    "    bbox_class: str\n",
    "    content: Union[ContentClass, str]\n",
    "    position: Position\n",
    "    score: str\n",
    "    scoreocr: str\n",
    "\n",
    "    def __init__(self, bbox_class: str, content: Union[ContentClass, str], position: Position, score: str, scoreocr: str) -> None:\n",
    "        self.bbox_class = bbox_class\n",
    "        self.content = content\n",
    "        self.position = position\n",
    "        self.score = score\n",
    "        self.scoreocr = scoreocr\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(obj: Any) -> 'Bbox':\n",
    "        assert isinstance(obj, dict)\n",
    "        bbox_class = from_str(obj.get(\"class\"))\n",
    "        content = from_union([ContentClass.from_dict, from_str], obj.get(\"content\"))\n",
    "        position = Position.from_dict(obj.get(\"position\"))\n",
    "        score = from_str(obj.get(\"score\"))\n",
    "        scoreocr = from_str(obj.get(\"scoreocr\"))\n",
    "        return Bbox(bbox_class, content, position, score, scoreocr)\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        result: dict = {}\n",
    "        result[\"class\"] = from_str(self.bbox_class)\n",
    "        result[\"content\"] = from_union([lambda x: to_class(ContentClass, x), from_str], self.content)\n",
    "        result[\"position\"] = to_class(Position, self.position)\n",
    "        result[\"score\"] = from_str(self.score)\n",
    "        result[\"scoreocr\"] = from_str(self.scoreocr)\n",
    "        return result\n",
    "\n",
    "\n",
    "class Page:\n",
    "    bbox: List[Bbox]\n",
    "    page: int\n",
    "    probability: float\n",
    "    type: str\n",
    "\n",
    "    def __init__(self, bbox: List[Bbox], page: int, probability: float, type: str) -> None:\n",
    "        self.bbox = bbox\n",
    "        self.page = page\n",
    "        self.probability = probability\n",
    "        self.type = type\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(obj: Any) -> 'Page':\n",
    "        assert isinstance(obj, dict)\n",
    "        bbox = from_list(Bbox.from_dict, obj.get(\"bbox\"))\n",
    "        page = int(from_str(obj.get(\"page\")))\n",
    "        probability = from_float(obj.get(\"probability\"))\n",
    "        type = from_str(obj.get(\"type\"))\n",
    "        return Page(bbox, page, probability, type)\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        result: dict = {}\n",
    "        result[\"bbox\"] = from_list(lambda x: to_class(Bbox, x), self.bbox)\n",
    "        result[\"page\"] = from_str(str(self.page))\n",
    "        result[\"probability\"] = to_float(self.probability)\n",
    "        result[\"type\"] = from_str(self.type)\n",
    "        return result\n",
    "\n",
    "\n",
    "class PuneHedgehog:\n",
    "    value: str\n",
    "\n",
    "    def __init__(self, value: str) -> None:\n",
    "        self.value = value\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(obj: Any) -> 'PuneHedgehog':\n",
    "        assert isinstance(obj, dict)\n",
    "        value = from_str(obj.get(\"VALUE\"))\n",
    "        return PuneHedgehog(value)\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        result: dict = {}\n",
    "        result[\"VALUE\"] = from_str(self.value)\n",
    "        return result\n",
    "\n",
    "\n",
    "class Rf1:\n",
    "    rf1_doc: PuneHedgehog\n",
    "    rf1_ht: PuneHedgehog\n",
    "    value: bool\n",
    "\n",
    "    def __init__(self, rf1_doc: PuneHedgehog, rf1_ht: PuneHedgehog, value: bool) -> None:\n",
    "        self.rf1_doc = rf1_doc\n",
    "        self.rf1_ht = rf1_ht\n",
    "        self.value = value\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(obj: Any) -> 'Rf1':\n",
    "        assert isinstance(obj, dict)\n",
    "        rf1_doc = PuneHedgehog.from_dict(obj.get(\"RF1_DOC\"))\n",
    "        rf1_ht = PuneHedgehog.from_dict(obj.get(\"RF1_HT\"))\n",
    "        value = from_bool(obj.get(\"VALUE\"))\n",
    "        return Rf1(rf1_doc, rf1_ht, value)\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        result: dict = {}\n",
    "        result[\"RF1_DOC\"] = to_class(PuneHedgehog, self.rf1_doc)\n",
    "        result[\"RF1_HT\"] = to_class(PuneHedgehog, self.rf1_ht)\n",
    "        result[\"VALUE\"] = from_bool(self.value)\n",
    "        return result\n",
    "\n",
    "\n",
    "class Rf2:\n",
    "    rf2_f: PuneHedgehog\n",
    "    rf2_numreg: PuneHedgehog\n",
    "    rf2_qt1: PuneHedgehog\n",
    "    rf2_qte: PuneHedgehog\n",
    "    rf2_upe: PuneHedgehog\n",
    "    value: bool\n",
    "\n",
    "    def __init__(self, rf2_f: PuneHedgehog, rf2_numreg: PuneHedgehog, rf2_qt1: PuneHedgehog, rf2_qte: PuneHedgehog, rf2_upe: PuneHedgehog, value: bool) -> None:\n",
    "        self.rf2_f = rf2_f\n",
    "        self.rf2_numreg = rf2_numreg\n",
    "        self.rf2_qt1 = rf2_qt1\n",
    "        self.rf2_qte = rf2_qte\n",
    "        self.rf2_upe = rf2_upe\n",
    "        self.value = value\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(obj: Any) -> 'Rf2':\n",
    "        assert isinstance(obj, dict)\n",
    "        rf2_f = PuneHedgehog.from_dict(obj.get(\"RF2_F\"))\n",
    "        rf2_numreg = PuneHedgehog.from_dict(obj.get(\"RF2_NUMREG\"))\n",
    "        rf2_qt1 = PuneHedgehog.from_dict(obj.get(\"RF2_QT1\"))\n",
    "        rf2_qte = PuneHedgehog.from_dict(obj.get(\"RF2_QTE\"))\n",
    "        rf2_upe = PuneHedgehog.from_dict(obj.get(\"RF2_UPE\"))\n",
    "        value = from_bool(obj.get(\"VALUE\"))\n",
    "        return Rf2(rf2_f, rf2_numreg, rf2_qt1, rf2_qte, rf2_upe, value)\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        result: dict = {}\n",
    "        result[\"RF2_F\"] = to_class(PuneHedgehog, self.rf2_f)\n",
    "        result[\"RF2_NUMREG\"] = to_class(PuneHedgehog, self.rf2_numreg)\n",
    "        result[\"RF2_QT1\"] = to_class(PuneHedgehog, self.rf2_qt1)\n",
    "        result[\"RF2_QTE\"] = to_class(PuneHedgehog, self.rf2_qte)\n",
    "        result[\"RF2_UPE\"] = to_class(PuneHedgehog, self.rf2_upe)\n",
    "        result[\"VALUE\"] = from_bool(self.value)\n",
    "        return result\n",
    "\n",
    "\n",
    "class Rf3:\n",
    "    rf3_aut1: PuneHedgehog\n",
    "    rf3_aut1_np: PuneHedgehog\n",
    "    rf3_aut1_total: PuneHedgehog\n",
    "    rf3_aut2: PuneHedgehog\n",
    "    rf3_aut2_np: PuneHedgehog\n",
    "    rf3_aut2_total: PuneHedgehog\n",
    "    rf3_aut3: PuneHedgehog\n",
    "    rf3_aut3_np: PuneHedgehog\n",
    "    rf3_aut3_total: PuneHedgehog\n",
    "    value: bool\n",
    "\n",
    "    def __init__(self, rf3_aut1: PuneHedgehog, rf3_aut1_np: PuneHedgehog, rf3_aut1_total: PuneHedgehog, rf3_aut2: PuneHedgehog, rf3_aut2_np: PuneHedgehog, rf3_aut2_total: PuneHedgehog, rf3_aut3: PuneHedgehog, rf3_aut3_np: PuneHedgehog, rf3_aut3_total: PuneHedgehog, value: bool) -> None:\n",
    "        self.rf3_aut1 = rf3_aut1\n",
    "        self.rf3_aut1_np = rf3_aut1_np\n",
    "        self.rf3_aut1_total = rf3_aut1_total\n",
    "        self.rf3_aut2 = rf3_aut2\n",
    "        self.rf3_aut2_np = rf3_aut2_np\n",
    "        self.rf3_aut2_total = rf3_aut2_total\n",
    "        self.rf3_aut3 = rf3_aut3\n",
    "        self.rf3_aut3_np = rf3_aut3_np\n",
    "        self.rf3_aut3_total = rf3_aut3_total\n",
    "        self.value = value\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(obj: Any) -> 'Rf3':\n",
    "        assert isinstance(obj, dict)\n",
    "        rf3_aut1 = PuneHedgehog.from_dict(obj.get(\"RF3_AUT1\"))\n",
    "        rf3_aut1_np = PuneHedgehog.from_dict(obj.get(\"RF3_AUT1_NP\"))\n",
    "        rf3_aut1_total = PuneHedgehog.from_dict(obj.get(\"RF3_AUT1_TOTAL\"))\n",
    "        rf3_aut2 = PuneHedgehog.from_dict(obj.get(\"RF3_AUT2\"))\n",
    "        rf3_aut2_np = PuneHedgehog.from_dict(obj.get(\"RF3_AUT2_NP\"))\n",
    "        rf3_aut2_total = PuneHedgehog.from_dict(obj.get(\"RF3_AUT2_TOTAL\"))\n",
    "        rf3_aut3 = PuneHedgehog.from_dict(obj.get(\"RF3_AUT3\"))\n",
    "        rf3_aut3_np = PuneHedgehog.from_dict(obj.get(\"RF3_AUT3_NP\"))\n",
    "        rf3_aut3_total = PuneHedgehog.from_dict(obj.get(\"RF3_AUT3_TOTAL\"))\n",
    "        value = from_bool(obj.get(\"VALUE\"))\n",
    "        return Rf3(rf3_aut1, rf3_aut1_np, rf3_aut1_total, rf3_aut2, rf3_aut2_np, rf3_aut2_total, rf3_aut3, rf3_aut3_np, rf3_aut3_total, value)\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        result: dict = {}\n",
    "        result[\"RF3_AUT1\"] = to_class(PuneHedgehog, self.rf3_aut1)\n",
    "        result[\"RF3_AUT1_NP\"] = to_class(PuneHedgehog, self.rf3_aut1_np)\n",
    "        result[\"RF3_AUT1_TOTAL\"] = to_class(PuneHedgehog, self.rf3_aut1_total)\n",
    "        result[\"RF3_AUT2\"] = to_class(PuneHedgehog, self.rf3_aut2)\n",
    "        result[\"RF3_AUT2_NP\"] = to_class(PuneHedgehog, self.rf3_aut2_np)\n",
    "        result[\"RF3_AUT2_TOTAL\"] = to_class(PuneHedgehog, self.rf3_aut2_total)\n",
    "        result[\"RF3_AUT3\"] = to_class(PuneHedgehog, self.rf3_aut3)\n",
    "        result[\"RF3_AUT3_NP\"] = to_class(PuneHedgehog, self.rf3_aut3_np)\n",
    "        result[\"RF3_AUT3_TOTAL\"] = to_class(PuneHedgehog, self.rf3_aut3_total)\n",
    "        result[\"VALUE\"] = from_bool(self.value)\n",
    "        return result\n",
    "\n",
    "\n",
    "class TartuGecko:\n",
    "    active: bool\n",
    "    value: str\n",
    "\n",
    "    def __init__(self, active: bool, value: str) -> None:\n",
    "        self.active = active\n",
    "        self.value = value\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(obj: Any) -> 'TartuGecko':\n",
    "        assert isinstance(obj, dict)\n",
    "        active = from_bool(obj.get(\"ACTIVE\"))\n",
    "        value = from_str(obj.get(\"VALUE\"))\n",
    "        return TartuGecko(active, value)\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        result: dict = {}\n",
    "        result[\"ACTIVE\"] = from_bool(self.active)\n",
    "        result[\"VALUE\"] = from_str(self.value)\n",
    "        return result\n",
    "\n",
    "\n",
    "class Rf4:\n",
    "    rf4_no_principales: TartuGecko\n",
    "    rf4_no_principales_est: TartuGecko\n",
    "    rf4_peint001: TartuGecko\n",
    "    rf4_peint001_est: TartuGecko\n",
    "    rf4_peint003: TartuGecko\n",
    "    rf4_peint003_est: TartuGecko\n",
    "    rf4_peint004: TartuGecko\n",
    "    rf4_peint004_est: TartuGecko\n",
    "    rf4_plat001: TartuGecko\n",
    "    rf4_plat001_est: TartuGecko\n",
    "    rf4_plomb001: TartuGecko\n",
    "    rf4_plomb001_est: TartuGecko\n",
    "    value: bool\n",
    "\n",
    "    def __init__(self, rf4_no_principales: TartuGecko, rf4_no_principales_est: TartuGecko, rf4_peint001: TartuGecko, rf4_peint001_est: TartuGecko, rf4_peint003: TartuGecko, rf4_peint003_est: TartuGecko, rf4_peint004: TartuGecko, rf4_peint004_est: TartuGecko, rf4_plat001: TartuGecko, rf4_plat001_est: TartuGecko, rf4_plomb001: TartuGecko, rf4_plomb001_est: TartuGecko, value: bool) -> None:\n",
    "        self.rf4_no_principales = rf4_no_principales\n",
    "        self.rf4_no_principales_est = rf4_no_principales_est\n",
    "        self.rf4_peint001 = rf4_peint001\n",
    "        self.rf4_peint001_est = rf4_peint001_est\n",
    "        self.rf4_peint003 = rf4_peint003\n",
    "        self.rf4_peint003_est = rf4_peint003_est\n",
    "        self.rf4_peint004 = rf4_peint004\n",
    "        self.rf4_peint004_est = rf4_peint004_est\n",
    "        self.rf4_plat001 = rf4_plat001\n",
    "        self.rf4_plat001_est = rf4_plat001_est\n",
    "        self.rf4_plomb001 = rf4_plomb001\n",
    "        self.rf4_plomb001_est = rf4_plomb001_est\n",
    "        self.value = value\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(obj: Any) -> 'Rf4':\n",
    "        assert isinstance(obj, dict)\n",
    "        rf4_no_principales = TartuGecko.from_dict(obj.get(\"RF4_NO_PRINCIPALES\"))\n",
    "        rf4_no_principales_est = TartuGecko.from_dict(obj.get(\"RF4_NO_PRINCIPALES_EST\"))\n",
    "        rf4_peint001 = TartuGecko.from_dict(obj.get(\"RF4_PEINT001\"))\n",
    "        rf4_peint001_est = TartuGecko.from_dict(obj.get(\"RF4_PEINT001_EST\"))\n",
    "        rf4_peint003 = TartuGecko.from_dict(obj.get(\"RF4_PEINT003\"))\n",
    "        rf4_peint003_est = TartuGecko.from_dict(obj.get(\"RF4_PEINT003_EST\"))\n",
    "        rf4_peint004 = TartuGecko.from_dict(obj.get(\"RF4_PEINT004\"))\n",
    "        rf4_peint004_est = TartuGecko.from_dict(obj.get(\"RF4_PEINT004_EST\"))\n",
    "        rf4_plat001 = TartuGecko.from_dict(obj.get(\"RF4_PLAT001\"))\n",
    "        rf4_plat001_est = TartuGecko.from_dict(obj.get(\"RF4_PLAT001_EST\"))\n",
    "        rf4_plomb001 = TartuGecko.from_dict(obj.get(\"RF4_PLOMB001\"))\n",
    "        rf4_plomb001_est = TartuGecko.from_dict(obj.get(\"RF4_PLOMB001_EST\"))\n",
    "        value = from_bool(obj.get(\"VALUE\"))\n",
    "        return Rf4(rf4_no_principales, rf4_no_principales_est, rf4_peint001, rf4_peint001_est, rf4_peint003, rf4_peint003_est, rf4_peint004, rf4_peint004_est, rf4_plat001, rf4_plat001_est, rf4_plomb001, rf4_plomb001_est, value)\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        result: dict = {}\n",
    "        result[\"RF4_NO_PRINCIPALES\"] = to_class(TartuGecko, self.rf4_no_principales)\n",
    "        result[\"RF4_NO_PRINCIPALES_EST\"] = to_class(TartuGecko, self.rf4_no_principales_est)\n",
    "        result[\"RF4_PEINT001\"] = to_class(TartuGecko, self.rf4_peint001)\n",
    "        result[\"RF4_PEINT001_EST\"] = to_class(TartuGecko, self.rf4_peint001_est)\n",
    "        result[\"RF4_PEINT003\"] = to_class(TartuGecko, self.rf4_peint003)\n",
    "        result[\"RF4_PEINT003_EST\"] = to_class(TartuGecko, self.rf4_peint003_est)\n",
    "        result[\"RF4_PEINT004\"] = to_class(TartuGecko, self.rf4_peint004)\n",
    "        result[\"RF4_PEINT004_EST\"] = to_class(TartuGecko, self.rf4_peint004_est)\n",
    "        result[\"RF4_PLAT001\"] = to_class(TartuGecko, self.rf4_plat001)\n",
    "        result[\"RF4_PLAT001_EST\"] = to_class(TartuGecko, self.rf4_plat001_est)\n",
    "        result[\"RF4_PLOMB001\"] = to_class(TartuGecko, self.rf4_plomb001)\n",
    "        result[\"RF4_PLOMB001_EST\"] = to_class(TartuGecko, self.rf4_plomb001_est)\n",
    "        result[\"VALUE\"] = from_bool(self.value)\n",
    "        return result\n",
    "\n",
    "\n",
    "class Rf5:\n",
    "    rf5_fourniture: PuneHedgehog\n",
    "    rf5_fourniture_est: PuneHedgehog\n",
    "    rf5_mo000: TartuGecko\n",
    "    rf5_mo000_est: TartuGecko\n",
    "    rf5_no_principales: TartuGecko\n",
    "    rf5_no_principales_est: TartuGecko\n",
    "    rf5_peint001: TartuGecko\n",
    "    rf5_peint001_est: TartuGecko\n",
    "    rf5_peint003: TartuGecko\n",
    "    rf5_peint003_est: TartuGecko\n",
    "    rf5_peint004: TartuGecko\n",
    "    rf5_peint004_est: TartuGecko\n",
    "    rf5_peint_autre: PuneHedgehog\n",
    "    rf5_peint_autre_est: PuneHedgehog\n",
    "    rf5_plat001: TartuGecko\n",
    "    rf5_plat001_est: TartuGecko\n",
    "    rf5_plat002: PuneHedgehog\n",
    "    rf5_plat002_est: PuneHedgehog\n",
    "    rf5_plomb001: TartuGecko\n",
    "    rf5_plomb001_est: TartuGecko\n",
    "    value: bool\n",
    "\n",
    "    def __init__(self, rf5_fourniture: PuneHedgehog, rf5_fourniture_est: PuneHedgehog, rf5_mo000: TartuGecko, rf5_mo000_est: TartuGecko, rf5_no_principales: TartuGecko, rf5_no_principales_est: TartuGecko, rf5_peint001: TartuGecko, rf5_peint001_est: TartuGecko, rf5_peint003: TartuGecko, rf5_peint003_est: TartuGecko, rf5_peint004: TartuGecko, rf5_peint004_est: TartuGecko, rf5_peint_autre: PuneHedgehog, rf5_peint_autre_est: PuneHedgehog, rf5_plat001: TartuGecko, rf5_plat001_est: TartuGecko, rf5_plat002: PuneHedgehog, rf5_plat002_est: PuneHedgehog, rf5_plomb001: TartuGecko, rf5_plomb001_est: TartuGecko, value: bool) -> None:\n",
    "        self.rf5_fourniture = rf5_fourniture\n",
    "        self.rf5_fourniture_est = rf5_fourniture_est\n",
    "        self.rf5_mo000 = rf5_mo000\n",
    "        self.rf5_mo000_est = rf5_mo000_est\n",
    "        self.rf5_no_principales = rf5_no_principales\n",
    "        self.rf5_no_principales_est = rf5_no_principales_est\n",
    "        self.rf5_peint001 = rf5_peint001\n",
    "        self.rf5_peint001_est = rf5_peint001_est\n",
    "        self.rf5_peint003 = rf5_peint003\n",
    "        self.rf5_peint003_est = rf5_peint003_est\n",
    "        self.rf5_peint004 = rf5_peint004\n",
    "        self.rf5_peint004_est = rf5_peint004_est\n",
    "        self.rf5_peint_autre = rf5_peint_autre\n",
    "        self.rf5_peint_autre_est = rf5_peint_autre_est\n",
    "        self.rf5_plat001 = rf5_plat001\n",
    "        self.rf5_plat001_est = rf5_plat001_est\n",
    "        self.rf5_plat002 = rf5_plat002\n",
    "        self.rf5_plat002_est = rf5_plat002_est\n",
    "        self.rf5_plomb001 = rf5_plomb001\n",
    "        self.rf5_plomb001_est = rf5_plomb001_est\n",
    "        self.value = value\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(obj: Any) -> 'Rf5':\n",
    "        assert isinstance(obj, dict)\n",
    "        rf5_fourniture = PuneHedgehog.from_dict(obj.get(\"RF5_FOURNITURE\"))\n",
    "        rf5_fourniture_est = PuneHedgehog.from_dict(obj.get(\"RF5_FOURNITURE_EST\"))\n",
    "        rf5_mo000 = TartuGecko.from_dict(obj.get(\"RF5_MO000\"))\n",
    "        rf5_mo000_est = TartuGecko.from_dict(obj.get(\"RF5_MO000_EST\"))\n",
    "        rf5_no_principales = TartuGecko.from_dict(obj.get(\"RF5_NO_PRINCIPALES\"))\n",
    "        rf5_no_principales_est = TartuGecko.from_dict(obj.get(\"RF5_NO_PRINCIPALES_EST\"))\n",
    "        rf5_peint001 = TartuGecko.from_dict(obj.get(\"RF5_PEINT001\"))\n",
    "        rf5_peint001_est = TartuGecko.from_dict(obj.get(\"RF5_PEINT001_EST\"))\n",
    "        rf5_peint003 = TartuGecko.from_dict(obj.get(\"RF5_PEINT003\"))\n",
    "        rf5_peint003_est = TartuGecko.from_dict(obj.get(\"RF5_PEINT003_EST\"))\n",
    "        rf5_peint004 = TartuGecko.from_dict(obj.get(\"RF5_PEINT004\"))\n",
    "        rf5_peint004_est = TartuGecko.from_dict(obj.get(\"RF5_PEINT004_EST\"))\n",
    "        rf5_peint_autre = PuneHedgehog.from_dict(obj.get(\"RF5_PEINT_AUTRE\"))\n",
    "        rf5_peint_autre_est = PuneHedgehog.from_dict(obj.get(\"RF5_PEINT_AUTRE_EST\"))\n",
    "        rf5_plat001 = TartuGecko.from_dict(obj.get(\"RF5_PLAT001\"))\n",
    "        rf5_plat001_est = TartuGecko.from_dict(obj.get(\"RF5_PLAT001_EST\"))\n",
    "        rf5_plat002 = PuneHedgehog.from_dict(obj.get(\"RF5_PLAT002\"))\n",
    "        rf5_plat002_est = PuneHedgehog.from_dict(obj.get(\"RF5_PLAT002_EST\"))\n",
    "        rf5_plomb001 = TartuGecko.from_dict(obj.get(\"RF5_PLOMB001\"))\n",
    "        rf5_plomb001_est = TartuGecko.from_dict(obj.get(\"RF5_PLOMB001_EST\"))\n",
    "        value = from_bool(obj.get(\"VALUE\"))\n",
    "        return Rf5(rf5_fourniture, rf5_fourniture_est, rf5_mo000, rf5_mo000_est, rf5_no_principales, rf5_no_principales_est, rf5_peint001, rf5_peint001_est, rf5_peint003, rf5_peint003_est, rf5_peint004, rf5_peint004_est, rf5_peint_autre, rf5_peint_autre_est, rf5_plat001, rf5_plat001_est, rf5_plat002, rf5_plat002_est, rf5_plomb001, rf5_plomb001_est, value)\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        result: dict = {}\n",
    "        result[\"RF5_FOURNITURE\"] = to_class(PuneHedgehog, self.rf5_fourniture)\n",
    "        result[\"RF5_FOURNITURE_EST\"] = to_class(PuneHedgehog, self.rf5_fourniture_est)\n",
    "        result[\"RF5_MO000\"] = to_class(TartuGecko, self.rf5_mo000)\n",
    "        result[\"RF5_MO000_EST\"] = to_class(TartuGecko, self.rf5_mo000_est)\n",
    "        result[\"RF5_NO_PRINCIPALES\"] = to_class(TartuGecko, self.rf5_no_principales)\n",
    "        result[\"RF5_NO_PRINCIPALES_EST\"] = to_class(TartuGecko, self.rf5_no_principales_est)\n",
    "        result[\"RF5_PEINT001\"] = to_class(TartuGecko, self.rf5_peint001)\n",
    "        result[\"RF5_PEINT001_EST\"] = to_class(TartuGecko, self.rf5_peint001_est)\n",
    "        result[\"RF5_PEINT003\"] = to_class(TartuGecko, self.rf5_peint003)\n",
    "        result[\"RF5_PEINT003_EST\"] = to_class(TartuGecko, self.rf5_peint003_est)\n",
    "        result[\"RF5_PEINT004\"] = to_class(TartuGecko, self.rf5_peint004)\n",
    "        result[\"RF5_PEINT004_EST\"] = to_class(TartuGecko, self.rf5_peint004_est)\n",
    "        result[\"RF5_PEINT_AUTRE\"] = to_class(PuneHedgehog, self.rf5_peint_autre)\n",
    "        result[\"RF5_PEINT_AUTRE_EST\"] = to_class(PuneHedgehog, self.rf5_peint_autre_est)\n",
    "        result[\"RF5_PLAT001\"] = to_class(TartuGecko, self.rf5_plat001)\n",
    "        result[\"RF5_PLAT001_EST\"] = to_class(TartuGecko, self.rf5_plat001_est)\n",
    "        result[\"RF5_PLAT002\"] = to_class(PuneHedgehog, self.rf5_plat002)\n",
    "        result[\"RF5_PLAT002_EST\"] = to_class(PuneHedgehog, self.rf5_plat002_est)\n",
    "        result[\"RF5_PLOMB001\"] = to_class(TartuGecko, self.rf5_plomb001)\n",
    "        result[\"RF5_PLOMB001_EST\"] = to_class(TartuGecko, self.rf5_plomb001_est)\n",
    "        result[\"VALUE\"] = from_bool(self.value)\n",
    "        return result\n",
    "\n",
    "\n",
    "class RedFlags:\n",
    "    rf1: Rf1\n",
    "    rf2: Rf2\n",
    "    rf3: Rf3\n",
    "    rf4: Rf4\n",
    "    rf5: Rf5\n",
    "\n",
    "    def __init__(self, rf1: Rf1, rf2: Rf2, rf3: Rf3, rf4: Rf4, rf5: Rf5) -> None:\n",
    "        self.rf1 = rf1\n",
    "        self.rf2 = rf2\n",
    "        self.rf3 = rf3\n",
    "        self.rf4 = rf4\n",
    "        self.rf5 = rf5\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(obj: Any) -> 'RedFlags':\n",
    "        assert isinstance(obj, dict)\n",
    "        rf1 = Rf1.from_dict(obj.get(\"RF1\"))\n",
    "        rf2 = Rf2.from_dict(obj.get(\"RF2\"))\n",
    "        rf3 = Rf3.from_dict(obj.get(\"RF3\"))\n",
    "        rf4 = Rf4.from_dict(obj.get(\"RF4\"))\n",
    "        rf5 = Rf5.from_dict(obj.get(\"RF5\"))\n",
    "        return RedFlags(rf1, rf2, rf3, rf4, rf5)\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        result: dict = {}\n",
    "        result[\"RF1\"] = to_class(Rf1, self.rf1)\n",
    "        result[\"RF2\"] = to_class(Rf2, self.rf2)\n",
    "        result[\"RF3\"] = to_class(Rf3, self.rf3)\n",
    "        result[\"RF4\"] = to_class(Rf4, self.rf4)\n",
    "        result[\"RF5\"] = to_class(Rf5, self.rf5)\n",
    "        return result\n",
    "\n",
    "\n",
    "class Output:\n",
    "    n_pages: int\n",
    "    pages: List[Page]\n",
    "    red_flags: RedFlags\n",
    "\n",
    "    def __init__(self, n_pages: int, pages: List[Page], red_flags: RedFlags) -> None:\n",
    "        self.n_pages = n_pages\n",
    "        self.pages = pages\n",
    "        self.red_flags = red_flags\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(obj: Any) -> 'Output':\n",
    "        assert isinstance(obj, dict)\n",
    "        n_pages = from_int(obj.get(\"n_pages\"))\n",
    "        pages = from_list(Page.from_dict, obj.get(\"pages\"))\n",
    "        red_flags = RedFlags.from_dict(obj.get(\"red_flags\"))\n",
    "        return Output(n_pages, pages, red_flags)\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        result: dict = {}\n",
    "        result[\"n_pages\"] = from_int(self.n_pages)\n",
    "        result[\"pages\"] = from_list(lambda x: to_class(Page, x), self.pages)\n",
    "        result[\"red_flags\"] = to_class(RedFlags, self.red_flags)\n",
    "        return result\n",
    "\n",
    "\n",
    "class Welcome:\n",
    "    action: str\n",
    "    welcome_datetime: datetime\n",
    "    elapsed: int\n",
    "    error: int\n",
    "    fileid: str\n",
    "    output: Output\n",
    "\n",
    "    def __init__(self, action: str, welcome_datetime: datetime, elapsed: int, error: int, fileid: str, output: Output) -> None:\n",
    "        self.action = action\n",
    "        self.welcome_datetime = welcome_datetime\n",
    "        self.elapsed = elapsed\n",
    "        self.error = error\n",
    "        self.fileid = fileid\n",
    "        self.output = output\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(obj: Any) -> 'Welcome':\n",
    "        assert isinstance(obj, dict)\n",
    "        action = from_str(obj.get(\"action\"))\n",
    "        welcome_datetime = from_datetime(obj.get(\"datetime\"))\n",
    "        elapsed = from_int(obj.get(\"elapsed\"))\n",
    "        error = from_int(obj.get(\"error\"))\n",
    "        fileid = from_str(obj.get(\"fileid\"))\n",
    "        output = Output.from_dict(obj.get(\"output\"))\n",
    "        return Welcome(action, welcome_datetime, elapsed, error, fileid, output)\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        result: dict = {}\n",
    "        result[\"action\"] = from_str(self.action)\n",
    "        result[\"datetime\"] = self.welcome_datetime.isoformat()\n",
    "        result[\"elapsed\"] = from_int(self.elapsed)\n",
    "        result[\"error\"] = from_int(self.error)\n",
    "        result[\"fileid\"] = from_str(self.fileid)\n",
    "        result[\"output\"] = to_class(Output, self.output)\n",
    "        return result\n",
    "\n",
    "\n",
    "def welcome_from_dict(s: Any) -> Welcome:\n",
    "    return Welcome.from_dict(s)\n",
    "\n",
    "\n",
    "def welcome_to_dict(x: Welcome) -> Any:\n",
    "    return to_class(Welcome, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "UMBRAL_1 = 500\n",
    "\n",
    "MINIMUM_DISTANCE = 3\n",
    "#Se establecen unos precios mínimo y máximo para los totales de las facturas\n",
    "MINIMUM_TOTAL = 99.99\n",
    "MAXIMUM_TOTAL = 100000.01\n",
    "#Umbrales fijados para el cálculo de los RFs\n",
    "RF1_HT = 1200\n",
    "RF3_AUT = 200\n",
    "cols_ref_prix = ['PEINT001', 'PEINT003', 'PEINT004', 'PLAT001', 'PLOMB001', 'MO000', 'NO_PRINCIPALES']\n",
    "RF4_UNITPRICE_VALUES = [21, 28, 21, 36, 400, 50, 100]\n",
    "RF5_UNITPRICE_VALUES  = [21,28,21,36,400,50,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_ok(total):\n",
    "    total = total.replace(',','.')\n",
    "    num_point = total.count('.')\n",
    "    # SI ES DEL TIPO 1.000.00\n",
    "    if(num_point > 1):\n",
    "        total = float(int(total.replace('.', ''))/100)\n",
    "        \n",
    "    # SI ES DEL TIPO 1.000 o 100.00\n",
    "    elif(num_point == 1):\n",
    "        # SI ES DEL TIPO 1.000\n",
    "        if(len(total.split('.')[-1])>2):\n",
    "            total = float(total.replace('.', ''))\n",
    "        # SI ES DEL TIPO 100.00\n",
    "        else:\n",
    "            total = float(int(total.replace('.', ''))/100)\n",
    "    # SI ES DEL TIPO 100        \n",
    "    else:\n",
    "        total = float(total.replace('.', ''))\n",
    "        \n",
    "    if((total > MINIMUM_TOTAL) and (total < MAXIMUM_TOTAL)):\n",
    "        return total\n",
    "    \n",
    "    return np.nan\n",
    "        \n",
    "def distance_to_word(x, word):\n",
    "    y = [y for y in x.lower().split(' ')]\n",
    "    r = [edit_distance(z, word, transpositions=True) for z in y]\n",
    "    \n",
    "    if(len(r) != 0):        \n",
    "        return (min(r))\n",
    "    return 99\n",
    "\n",
    "def get_pandas_out_of_json(data):\n",
    "    array = []\n",
    "    \n",
    "    #print('data: ', data)\n",
    "    for page in data['output']['pages']:\n",
    "        df_page = pd.DataFrame.from_dict(page)\n",
    "        \n",
    "        total_full_price = 0\n",
    "        total_full_score = 0\n",
    "        total_full_ocr_score = 0\n",
    "        total_ttc_full_price = 0\n",
    "        total_ttc_full_score = 0\n",
    "        total_ttc_full_ocr_score = 0\n",
    "        x_min_total= 0\n",
    "        x_max_total= 0\n",
    "        y_min_total= 0\n",
    "        y_max_total= 0\n",
    "        emiter = 0\n",
    "        score_emitter = 0\n",
    "        score_ocr_emitter = 0\n",
    "        x_min_emiter= 0\n",
    "        x_max_emiter= 0\n",
    "        y_min_emiter= 0\n",
    "        y_max_emiter= 0\n",
    "        siret =  0\n",
    "        score_siret = 0\n",
    "        score_ocr_siret = 0\n",
    "        x_min_siret= 0\n",
    "        x_max_siret= 0\n",
    "        y_min_siret= 0\n",
    "        y_max_siret= 0\n",
    "        recipient = 0\n",
    "        score_recipient = 0\n",
    "        score_ocr_recipient = 0\n",
    "        x_min_recipient= 0\n",
    "        x_max_recipient= 0\n",
    "        y_min_recipient= 0\n",
    "        y_max_recipient= 0\n",
    "\n",
    "        for bbox in df_page['bbox']:\n",
    "            \n",
    "            if(bbox['class'] == 'total'):\n",
    "                total_full_price = bbox['content']\n",
    "                total_full_score = bbox['score']\n",
    "                total_full_ocr_score = bbox['scoreocr']\n",
    "                x_min_total=bbox['position']['xmin']\n",
    "                x_max_total=bbox['position']['xmax']\n",
    "                y_min_total=bbox['position']['ymin']\n",
    "                y_max_total=bbox['position']['ymax']\n",
    "                \n",
    "            if('total_aux' in bbox['class']):\n",
    "                total_ttc_full_price = bbox['content']\n",
    "                total_ttc_full_score = bbox['score']\n",
    "                total_ttc_full_ocr_score = bbox['scoreocr']\n",
    "                \n",
    "            if('emitter' in bbox['class']):\n",
    "                emiter = bbox['content']\n",
    "                score_emitter = bbox['score']\n",
    "                score_ocr_emitter = bbox['scoreocr']\n",
    "                x_min_emiter=bbox['position']['xmin']\n",
    "                x_max_emiter=bbox['position']['xmax']\n",
    "                y_min_emiter=bbox['position']['ymin']\n",
    "                y_max_emiter=bbox['position']['ymax']\n",
    "                \n",
    "            if('siret' in bbox['class']):\n",
    "                siret = bbox['content']\n",
    "                score_siret = bbox['score']\n",
    "                score_ocr_siret = bbox['scoreocr']\n",
    "                x_min_siret=bbox['position']['xmin']\n",
    "                x_max_siret=bbox['position']['xmax']\n",
    "                y_min_siret=bbox['position']['ymin']\n",
    "                y_max_siret=bbox['position']['ymax']\n",
    "            \n",
    "            if('recipient' in bbox['class']):\n",
    "                recipient = bbox['content']\n",
    "                score_recipient = bbox['score']\n",
    "                score_ocr_recipient = bbox['scoreocr']\n",
    "                x_min_recipient=bbox['position']['xmin']\n",
    "                x_max_recipient=bbox['position']['xmax']\n",
    "                y_min_recipient=bbox['position']['ymin']\n",
    "                y_max_recipient=bbox['position']['ymax']\n",
    "                \n",
    "        for bbox in df_page['bbox']:\n",
    "            if('body' in bbox['class']):\n",
    "                df_record = pd.DataFrame.from_dict(bbox['content'])\n",
    "\n",
    "                body_found = 1 if (bbox['score'] == bbox['score']) else 0\n",
    "                body_score = bbox['score']\n",
    "                body_score_ocr = bbox['scoreocr']\n",
    "                x_min_body=bbox['position']['xmin']\n",
    "                x_max_body=bbox['position']['xmax']\n",
    "                y_min_body=bbox['position']['ymin']\n",
    "                y_max_body=bbox['position']['ymax']\n",
    "\n",
    "                if(df_record.shape[0] > 0):\n",
    "                    n_records = df_record['n_records'][0]                \n",
    "                    for i, record in enumerate(df_record['records']):                    \n",
    "\n",
    "                        text_value = dict(record['text'])['content']\n",
    "                        text_score = dict(record['text'])['score']\n",
    "                        total_value = dict(record['total_prix'])['content']\n",
    "                        total_score = dict(record['total_prix'])['score']\n",
    "                        unitprix_value = dict(record['unit_prix'])['content']\n",
    "                        unitprix_score = dict(record['unit_prix'])['score']\n",
    "                        quantite_value = dict(record['quantite'])['content']\n",
    "                        quantite_score = dict(record['quantite'])['score']\n",
    "                        units_value = dict(record['units'])['content']\n",
    "                        units_score = dict(record['units'])['score']\n",
    "                        \n",
    "                        text_quantite_value = dict(record['text_quantite'])['content']\n",
    "                        text_quantite_score = dict(record['text_quantite'])['score']\n",
    "                        text_units_value = dict(record['text_units'])['content']\n",
    "                        text_units_score = dict(record['text_units'])['score']\n",
    "                        unit_prix_text_value = dict(record['unit_prix_text'])['content']\n",
    "                        unit_prix_text_score = dict(record['unit_prix_text'])['score']\n",
    "\n",
    "                        h_x0 = record['H_X0']\n",
    "                        h_y0 = record['H_Y0']\n",
    "                        h_x1 = record['H_X1']\n",
    "                        h_y1 = record['H_Y1']\n",
    "                        \n",
    "                        n_agg_cat = record['n_agg_cat']\n",
    "                        agg_cat = []\n",
    "                        ref_price = []\n",
    "                        for i_agg in range(int(n_agg_cat)):\n",
    "                            agg_cat.append(dict(record['agg_cat'][i_agg])['cat'])\n",
    "                            ref_price.append(dict(record['agg_cat'][i_agg])['reference_price'])\n",
    "                                        \n",
    "                        n_categories_baremo = record['n_categories_baremo']\n",
    "                        \n",
    "                        category_value_0 = dict(record['categories'][0])['cat']\n",
    "                        category_score_0 = dict(record['categories'][0])['score']\n",
    "                        category_value_1 = dict(record['categories'][1])['cat']\n",
    "                        category_score_1 = dict(record['categories'][1])['score']\n",
    "                        category_value_2 = dict(record['categories'][2])['cat']\n",
    "                        category_score_2 = dict(record['categories'][2])['score']\n",
    "                        category_value_3 = dict(record['categories'][3])['cat']\n",
    "                        category_score_3 = dict(record['categories'][3])['score']\n",
    "                        category_value_4 = dict(record['categories'][4])['cat']\n",
    "                        category_score_4 = dict(record['categories'][4])['score']\n",
    "                        category_value_5 = dict(record['categories'][5])['cat']\n",
    "                        category_score_5 = dict(record['categories'][5])['score']\n",
    "                        category_value_6 = dict(record['categories'][6])['cat']\n",
    "                        category_score_6 = dict(record['categories'][6])['score']\n",
    "                        category_value_7 = dict(record['categories'][7])['cat']\n",
    "                        category_score_7 = dict(record['categories'][7])['score']\n",
    "                        category_value_8 = dict(record['categories'][8])['cat']\n",
    "                        category_score_8 = dict(record['categories'][8])['score']\n",
    "\n",
    "                        array.append([data['fileid'], \n",
    "                                      df_page.page[0], \n",
    "                                      df_page.type[0], \n",
    "                                      df_page.probability[0], \n",
    "                                      total_full_price,\n",
    "                                      total_full_score,\n",
    "                                      total_full_ocr_score,\n",
    "                                      total_ttc_full_price,\n",
    "                                      total_ttc_full_score,\n",
    "                                      total_ttc_full_ocr_score,\n",
    "                                      x_min_total,\n",
    "                                      x_max_total,\n",
    "                                      y_min_total,\n",
    "                                      y_max_total,\n",
    "                                      body_found, \n",
    "                                      body_score,\n",
    "                                      body_score_ocr,\n",
    "                                      x_min_body,\n",
    "                                      x_max_body,\n",
    "                                      y_min_body,\n",
    "                                      y_max_body,\n",
    "                                      siret,\n",
    "                                      score_siret,\n",
    "                                      score_ocr_siret,\n",
    "                                      x_min_siret,\n",
    "                                      x_max_siret,\n",
    "                                      y_min_siret,\n",
    "                                      y_max_siret,\n",
    "                                      recipient,\n",
    "                                      score_recipient,\n",
    "                                      score_ocr_recipient,\n",
    "                                      x_min_recipient,\n",
    "                                      x_max_recipient,\n",
    "                                      y_min_recipient,\n",
    "                                      y_max_recipient,\n",
    "                                      emiter,\n",
    "                                      score_emitter,\n",
    "                                      score_ocr_emitter,\n",
    "                                      x_min_emiter,\n",
    "                                      x_max_emiter,\n",
    "                                      y_min_emiter,\n",
    "                                      y_max_emiter,\n",
    "                                      n_records,\n",
    "                                      i,\n",
    "                                      text_value, \n",
    "                                      text_score,\n",
    "                                      units_value, \n",
    "                                      units_score,\n",
    "                                      quantite_value, \n",
    "                                      quantite_score,\n",
    "                                      unitprix_value, \n",
    "                                      unitprix_score,\n",
    "                                      total_value, \n",
    "                                      total_score,\n",
    "                                      text_quantite_value,\n",
    "                                      text_quantite_score,\n",
    "                                      text_units_value,\n",
    "                                      text_units_score,\n",
    "                                      unit_prix_text_value,\n",
    "                                      unit_prix_text_score,\n",
    "                                      h_x0,\n",
    "                                      h_y0,\n",
    "                                      h_x1,\n",
    "                                      h_y1,\n",
    "                                      agg_cat,\n",
    "                                      ref_price,\n",
    "                                      n_agg_cat,\n",
    "                                      n_categories_baremo, \n",
    "                                      category_value_0,\n",
    "                                      category_score_0, \n",
    "                                      category_value_1,\n",
    "                                      category_score_1, \n",
    "                                      category_value_2,\n",
    "                                      category_score_2, \n",
    "                                      category_value_3,\n",
    "                                      category_score_3, \n",
    "                                      category_value_4,\n",
    "                                      category_score_4,\n",
    "                                      category_value_5,\n",
    "                                      category_score_5,\n",
    "                                      category_value_6,\n",
    "                                      category_score_6,\n",
    "                                      category_value_7,\n",
    "                                      category_score_7,\n",
    "                                      category_value_8,\n",
    "                                      category_score_8\n",
    "                                     ])\n",
    "                else:                \n",
    "                    array.append([data['fileid'], \n",
    "                                  df_page.page[0], \n",
    "                                  df_page.type[0], \n",
    "                                  df_page.probability[0], \n",
    "                                  total_full_price,\n",
    "                                  total_full_score,\n",
    "                                  total_full_ocr_score,\n",
    "                                  total_ttc_full_price,\n",
    "                                  total_ttc_full_score,\n",
    "                                  total_ttc_full_ocr_score,\n",
    "                                  x_min_total,\n",
    "                                  x_max_total,\n",
    "                                  y_min_total,\n",
    "                                  y_max_total,\n",
    "                                  body_found, \n",
    "                                  body_score,\n",
    "                                  body_score_ocr,\n",
    "                                  x_min_body,\n",
    "                                  x_max_body,\n",
    "                                  y_min_body,\n",
    "                                  y_max_body,\n",
    "                                  siret,\n",
    "                                  score_siret,\n",
    "                                  score_ocr_siret,\n",
    "                                  x_min_siret,\n",
    "                                  x_max_siret,\n",
    "                                  y_min_siret,\n",
    "                                  y_max_siret,\n",
    "                                  recipient,\n",
    "                                  score_recipient,\n",
    "                                  score_ocr_recipient,\n",
    "                                  x_min_recipient,\n",
    "                                  x_max_recipient,\n",
    "                                  y_min_recipient,\n",
    "                                  y_max_recipient,\n",
    "                                  emiter,\n",
    "                                  score_emitter,\n",
    "                                  score_ocr_emitter,\n",
    "                                  x_min_emiter,\n",
    "                                  x_max_emiter,\n",
    "                                  y_min_emiter,\n",
    "                                  y_max_emiter,\n",
    "                                  0,\n",
    "                                  0,\n",
    "                                  None, \n",
    "                                  None,\n",
    "                                  None, \n",
    "                                  None,\n",
    "                                  None, \n",
    "                                  None,\n",
    "                                  None, \n",
    "                                  None,\n",
    "                                  None, \n",
    "                                  None,\n",
    "                                  None, \n",
    "                                  None,\n",
    "                                  None, \n",
    "                                  None,\n",
    "                                  None, \n",
    "                                  None,\n",
    "                                  None, \n",
    "                                  None,\n",
    "                                  None, \n",
    "                                  None,\n",
    "                                  None, \n",
    "                                  None,\n",
    "                                  None,\n",
    "                                  None,\n",
    "                                  None,\n",
    "                                  None,\n",
    "                                  None, \n",
    "                                  None,\n",
    "                                  None, \n",
    "                                  None,\n",
    "                                  None,\n",
    "                                  None,\n",
    "                                  None,\n",
    "                                  None,\n",
    "                                  None, \n",
    "                                  None,\n",
    "                                  None, \n",
    "                                  None,\n",
    "                                  None, \n",
    "                                  None,\n",
    "                                  None,\n",
    "                                  None,\n",
    "                                  ])\n",
    "\n",
    "    df = pd.DataFrame(array, columns=['ID DOC', 'PAGE', 'TYPE', 'SCORE TYPE', 'TOTAL PRICE', 'SCORE TOTAL PRICE', 'OCR SCORE TOTAL PRICE', \n",
    "                                      'TOTAL PRICE DOC', 'SCORE TOTAL PRICE DOC', 'OCR SCORE TOTAL PRICE DOC', 'X MIN TOTAL PRICE', \n",
    "                                      'X MAX TOTAL PRICE', 'Y MIN TOTAL PRICE', 'Y MAX TOTAL PRICE', 'BODY', 'SCORE BODY', 'OCR SCORE BODY', \n",
    "                                      'X MIN BODY', 'X MAX BODY', 'Y MIN BODY', 'Y MAX BODY', 'SIRET', 'SCORE SIRET', 'SCORE OCR SIRET', \n",
    "                                      'X MIN SIRET', 'X MAX SIRET', 'Y MIN SIRET', 'Y MAX SIRET', 'RECIPIENT', 'RECIPIENT SCORE', \n",
    "                                      'RECIPIENT OCR SCORE', 'X MIN RECIPIENT', 'X MAX RECIPIENT', 'Y MIN RECIPIENT', 'Y MAX RECIPIENT', \n",
    "                                      'EMITER', 'EMITER SCORE', 'EMITER OCR SCORE', 'X MIN EMITER', 'X MAX EMITER', 'Y MIN EMITER', \n",
    "                                      'Y MAX EMITER', 'NUM RECORDS', 'RECORD', 'TEXT RECORD', 'SCORE TEXT RECORD','UNITS', 'SCORE UNITS', \n",
    "                                      'QUANTITY', 'SCORE QUANTITY', 'UNIT PRICE','SCORE UNIT PRICE', 'TOTAL VALUE', 'SCORE TOTAL VALUE',\n",
    "                                      'TEXT QUANTITY VALUE', 'SCORE TEXT QUANTITY VALUE', 'TEXT UNITS VALUE', 'SCORE TEXT UNITS VALUE', \n",
    "                                      'TEXT UNIT PRIX VALUE', 'SCORE TEXT UNIT PRIX VALUE', 'H_X0','H_Y0','H_X1','H_Y1','AGGREGATED CATEGORY','REFERENCE PRIX',\n",
    "                                      'NUMERO BAREMOS AGREGADOS','NUMERO BAREMOS','CATEGORY MA 1',\n",
    "                                      'SCORE CATEGORY MA 1', 'CATEGORY MA 2', 'SCORE CATEGORY MA 2', 'CATEGORY MA 3', 'SCORE CATEGORY MA 3', 'CATEGORY MA 4', \n",
    "                                      'SCORE CATEGORY MA 4', 'CATEGORY MA 5', 'SCORE CATEGORY MA 5', 'CATEGORY MA 6', 'SCORE CATEGORY MA 6',\n",
    "                                      'CATEGORY MA 7', 'SCORE CATEGORY MA 7', 'CATEGORY MA 8', 'SCORE CATEGORY MA 8', 'CATEGORY MA 9',\n",
    "                                      'SCORE CATEGORY MA 9'])\n",
    "    return df\n",
    "\n",
    "def red_flags(df,a):   \n",
    "    df_total = df.copy()\n",
    "    df = df[df['NUM RECORDS']!=0]\n",
    "    dic4 = {}\n",
    "    dic5 = {}\n",
    "    for i in range(len(cols_ref_prix)):\n",
    "        dic4[cols_ref_prix[i]] = RF4_UNITPRICE_VALUES[i]\n",
    "        dic5[cols_ref_prix[i]] = RF5_UNITPRICE_VALUES[i]\n",
    "    redflag4 = []\n",
    "    redflag5 = []        \n",
    "    #Calcular las distancias a las palabras frofait, ens, for, f, ft en busca de forfaits.\n",
    "    df['UNITS'] = df['UNITS'].astype(str)\n",
    "    df['UNIT PRICE'] = df['UNIT PRICE'].astype(str)\n",
    "    df['QUANTITY'] = df['QUANTITY'].astype(str)\n",
    "    df['TEXT RECORD'] = df['TEXT RECORD'].astype(str)\n",
    "    df['TOTAL PRICE'] = df['TOTAL PRICE'].astype(str)\n",
    "    df['TOTAL PRICE DOC'] = df['TOTAL PRICE DOC'].astype(str)\n",
    "    \n",
    "    df['DISTANCE UNITS'] = df['UNITS'].apply(distance_to_word, args=['forfait'])\n",
    "    df['DISTANCE TEXT'] = df['TEXT RECORD'].apply(distance_to_word, args=['forfait'])\n",
    "    \n",
    "    df['DISTANCE UNITS ENS'] = df['UNITS'].apply(distance_to_word, args=['ens'])\n",
    "    df['DISTANCE TEXT ENS'] = df['TEXT RECORD'].apply(distance_to_word, args=['ens'])\n",
    "    \n",
    "    df['DISTANCE UNITS FOR'] = df['UNITS'].apply(distance_to_word, args=['for'])\n",
    "    \n",
    "    df['DISTANCE UNITS F'] = df['UNITS'].apply(distance_to_word, args=['f']) \n",
    "    df['DISTANCE UNITS FT'] = df['UNITS'].apply(distance_to_word, args=['ft'])\n",
    "    \n",
    "    df['DISTANCE UNITS F'] = df[['DISTANCE UNITS F','DISTANCE UNITS FT']].min(axis=1)\n",
    "    \n",
    "    df_2 = pd.DataFrame(data=[[False,0.0,0.0,False,0.0,0.0,0.0,0.0,0.0,0.0,False,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,False,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,False,False,False,False,False,False,False,False,False,False,False,False, False,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False]]\\\n",
    "                        , columns=['RF1','RF1_DOC','RF1_HT', 'RF2', 'RF2_SCORE', 'RF2_QT1', 'RF2_QTE', 'RF2_UPE', 'RF2_F', 'RF2_NUMREG','RF3','RF3_AUT1','RF3_AUT2','RF3_AUT3','RF3_AUT1_TOTAL','RF3_AUT2_TOTAL','RF3_AUT3_TOTAL','RF3_AUT1_NP','RF3_AUT2_NP','RF3_AUT3_NP',\\\n",
    "                                   'RF4','RF4_NO_PRINCIPALES','RF4_PEINT001','RF4_PEINT003','RF4_PEINT004','RF4_PLOMB001','RF4_PLAT001',\\\n",
    "                                   'RF4_NO_PRINCIPALES_EST','RF4_PEINT001_EST','RF4_PEINT003_EST','RF4_PEINT004_EST','RF4_PLOMB001_EST','RF4_PLAT001_EST',\\\n",
    "                                   'RF4_NO_PRINCIPALES_ACTIVATE','RF4_PEINT001_ACTIVATE','RF4_PEINT003_ACTIVATE','RF4_PEINT004_ACTIVATE','RF4_PLOMB001_ACTIVATE','RF4_PLAT001_ACTIVATE',\\\n",
    "                                   'RF4_NO_PRINCIPALES_EST_ACTIVATE','RF4_PEINT001_EST_ACTIVATE','RF4_PEINT003_EST_ACTIVATE','RF4_PEINT004_EST_ACTIVATE','RF4_PLOMB001_EST_ACTIVATE','RF4_PLAT001_EST_ACTIVATE',\\\n",
    "                                   'RF5','RF5_NO_PRINCIPALES','RF5_FOURNITURE','RF5_MO000','RF5_PEINT001','RF5_PEINT003','RF5_PEINT004','RF5_PEINT_AUTRE','RF5_PLOMB001','RF5_PLAT001','RF5_PLAT002',\\\n",
    "                                   'RF5_NO_PRINCIPALES_EST','RF5_FOURNITURE_EST','RF5_MO000_EST','RF5_PEINT001_EST','RF5_PEINT003_EST','RF5_PEINT004_EST','RF5_PEINT_AUTRE_EST','RF5_PLOMB001_EST','RF5_PLAT001_EST','RF5_PLAT002_EST',\\\n",
    "                                  'RF5_NO_PRINCIPALES_ACTIVATE','RF5_FOURNITURE_ACTIVATE','RF5_MO000_ACTIVATE','RF5_PEINT001_ACTIVATE','RF5_PEINT003_ACTIVATE','RF5_PEINT004_ACTIVATE','RF5_PEINT_AUTRE_ACTIVATE','RF5_PLOMB001_ACTIVATE','RF5_PLAT001_ACTIVATE','RF5_PLAT002_ACTIVATE',\\\n",
    "                                   'RF5_NO_PRINCIPALES_EST_ACTIVATE','RF5_FOURNITURE_EST_ACTIVATE','RF5_MO000_EST_ACTIVATE','RF5_PEINT001_EST_ACTIVATE','RF5_PEINT003_EST_ACTIVATE','RF5_PEINT004_EST_ACTIVATE','RF5_PEINT_AUTRE_EST_ACTIVATE','RF5_PLOMB001_EST_ACTIVATE','RF5_PLAT001_EST_ACTIVATE','RF5_PLAT002_EST_ACTIVATE'])\n",
    "  \n",
    "    #RED FLAG 1 (Se busca total y total HT en las columnas de totales)\n",
    "    df_total = df_total[['PAGE', 'TOTAL PRICE', 'TOTAL PRICE DOC', 'TYPE']].drop_duplicates().sort_values(by='PAGE', ascending=False)\n",
    "    total = np.nan\n",
    "    total_ht = np.nan\n",
    "    for idx, row in df_total.iterrows():\n",
    "        if((row['TOTAL PRICE'].lower() != 'nan')&(row['TYPE']!='none')):\n",
    "            t = total_ok(row['TOTAL PRICE'])\n",
    "            if(t == t):\n",
    "                total = t\n",
    "                total_ht = t\n",
    "                break\n",
    "                \n",
    "    if(total != total):            \n",
    "        for idx, row in df_total.iterrows():\n",
    "            if((row['TOTAL PRICE DOC'].lower() != 'nan')&(row['TYPE']!='none')):\n",
    "                t = total_ok(row['TOTAL PRICE DOC'])\n",
    "                if(t == t):\n",
    "                    total = t\n",
    "                    break\n",
    "    \n",
    "    if(total != total):\n",
    "        for idx, row in df_total.iterrows():\n",
    "            if((row['TOTAL PRICE'].lower() != 'nan')):\n",
    "                total_ht = total_ok(row['TOTAL PRICE'])\n",
    "                total = total_ok(row['TOTAL PRICE'])\n",
    "                break\n",
    "            if((row['TOTAL PRICE DOC'].lower() != 'nan')&(total != total)):\n",
    "                total = total_ok(row['TOTAL PRICE DOC'])\n",
    "                break\n",
    "    \n",
    "    df_2.at[0,'RF1_HT'] = total_ht\n",
    "    df_2.at[0,'RF1_DOC'] = total\n",
    "    \n",
    "    #RED FLAG 2\n",
    "    df_2.at[0,'RF2_NUMREG'] = df[df['NUM RECORDS']!=0].shape[0]\n",
    "    #Diferentes formas en las que se han encontrado el valor 1.\n",
    "    values = ['1', '1.', '1.0', '1,', '1,0','1.00','1,00']\n",
    "    df['QUANTITY'] = df['QUANTITY'].astype(str)\n",
    "    df['TEXT QUANTITY VALUE'] = df['TEXT QUANTITY VALUE'].astype(str)\n",
    "    df['UNIT PRICE'] = df['UNIT PRICE'].astype(str)\n",
    "    df['TEXT UNIT PRIX VALUE'] = df['TEXT UNIT PRIX VALUE'].astype(str)\n",
    "    #Eliminamos los registros que no tienen valor\n",
    "    df = df[(~(df['TOTAL VALUE'].isnull()))&(df['TOTAL VALUE'] != '')]\n",
    "    total_registres = df['TOTAL VALUE'].astype(float).sum() #Suma de los totales de los registros\n",
    "    if (total_registres>0):\n",
    "        df['QUANTITY'] = df['QUANTITY'].replace('','nan')\n",
    "        df['UNIT PRICE'] = df['UNIT PRICE'].replace('','nan')\n",
    "        df['TEXT QUANTITY VALUE'] = df['TEXT QUANTITY VALUE'].replace('','nan')\n",
    "        df['TEXT UNIT PRIX VALUE'] = df['TEXT UNIT PRIX VALUE'].replace('','nan')\n",
    "        df_2.at[0,'RF2_QT1'] = sum(df[(df['QUANTITY'].isin(values))&(df['TEXT QUANTITY VALUE'].isin(values+['nan'])) | (df['QUANTITY']=='nan')&((df['TEXT QUANTITY VALUE'].isin(values)))]['TOTAL VALUE'].astype(float))/total_registres #Peso de los registros con cantidad 1 respecto el total\n",
    "        df_2.at[0,'RF2_QTE'] = sum(df[(df['QUANTITY']=='nan')&(df['TEXT QUANTITY VALUE']=='nan')]['TOTAL VALUE'].astype(float))/total_registres #Peso de los registros con cantidad vacía respecto el total\n",
    "        df_2.at[0,'RF2_UPE'] = sum(df[(df['UNIT PRICE']=='nan')&(df['TEXT UNIT PRIX VALUE']=='nan')]['TOTAL VALUE'].astype(float))/total_registres #Peso de los registros con precio unitario vacío respecto el total\n",
    "        #Para cada registro se calcula si es forfait o no\n",
    "        df['F'] = (df['DISTANCE UNITS'] < MINIMUM_DISTANCE )\\\n",
    "               | (df['DISTANCE TEXT'] < MINIMUM_DISTANCE )\\\n",
    "               | (df['DISTANCE UNITS FOR'] < 2 ) \\\n",
    "               | (df['DISTANCE UNITS F'] < 1 )\\\n",
    "               | (df['DISTANCE TEXT ENS'] < 1 )\\\n",
    "               | (df['DISTANCE UNITS ENS'] < 1)\n",
    "        #Peso de los registros del tipo forfait respecto el total\n",
    "        df_2.at[0,'RF2_F'] = ((df['TOTAL VALUE'].astype(float)*df['F']).sum())/total_registres\n",
    "        \n",
    "        #RED FLAG 3\n",
    "        df_2.at[0,'RF3'] = 0\n",
    "        df = df.fillna('nan')\n",
    "               \n",
    "        if (df['TOTAL VALUE'].astype(float).sum()) > 0:\n",
    "            df['TOTAL VALUE'] = df['TOTAL VALUE'].astype(float)\n",
    "            #Suma de los totales de los registros cuyo baremo es AUTRE\n",
    "            df_2.at[0,'RF3_AUT1'] = df[df['AGGREGATED CATEGORY'].apply(lambda x: 'AUTRES001' in x)]['TOTAL VALUE'].sum()\n",
    "            df_2.at[0,'RF3_AUT2'] = df[df['AGGREGATED CATEGORY'].apply(lambda x: 'AUTRES002' in x)]['TOTAL VALUE'].sum()\n",
    "            df_2.at[0,'RF3_AUT3'] = df[df['AGGREGATED CATEGORY'].apply(lambda x: 'AUTRES003' in x)]['TOTAL VALUE'].sum()\n",
    "            \n",
    "            #Peso del precio de los registros cuyo baremo es AUTRE\n",
    "            df_2.at[0,'RF3_AUT1_TOTAL'] = (df_2['RF3_AUT1'].astype(float).values[0])/total_registres\n",
    "            df_2.at[0,'RF3_AUT2_TOTAL'] = (df_2['RF3_AUT2'].astype(float).values[0])/total_registres\n",
    "            df_2.at[0,'RF3_AUT3_TOTAL'] = (df_2['RF3_AUT3'].astype(float).values[0])/total_registres\n",
    "        \n",
    "            #Media de los registros cuyo baremo es AUTRE del total de registros\n",
    "            df_2.at[0,'RF3_AUT1_NP'] = (df_2['RF3_AUT1'].astype(float).values[0])/(df_2['RF2_NUMREG'].values[0])\n",
    "            df_2.at[0,'RF3_AUT2_NP'] = (df_2['RF3_AUT2'].astype(float).values[0])/(df_2['RF2_NUMREG'].values[0])\n",
    "            df_2.at[0,'RF3_AUT3_NP'] = (df_2['RF3_AUT3'].astype(float).values[0])/(df_2['RF2_NUMREG'].values[0])\n",
    "        #El Label 2 es el string concatenado de todos los labels\n",
    "        df['LABEL2'] = df['AGGREGATED CATEGORY'].apply(' '.join)\n",
    "        #Quantite conjunta de quant i text_qte\n",
    "        df['QUANTITY2'] = df.apply(returnQte,axis=1)\n",
    "        df['TOTAL_RF4'] = df['TOTAL VALUE'].copy().astype(float)\n",
    "        total_peintA = df[(df['LABEL2'].str.contains('PEINT_AUTRE'))]['TOTAL VALUE'].astype(float).sum()\n",
    "        df['PROP'] = 0.0\n",
    "        dfpeint = df[(df['LABEL2'].str.contains('PEINT00'))]\n",
    "        if (len(dfpeint)>0)&(total_peintA > 0):\n",
    "            dfpeint['PROP'] = dfpeint['TOTAL_RF4']/(dfpeint['TOTAL_RF4'].sum())\n",
    "            dfpeint['TOTAL_RF4'] =  dfpeint['TOTAL_RF4'] + total_peintA*dfpeint['PROP']\n",
    "            df = df[~(df['LABEL2'].str.contains('PEINT_AUTRE'))]      \n",
    "        #RED FLAGs 4 y 5\n",
    "        catsRF4 = ['NO_PRINCIPALES','PEINT001','PEINT003','PEINT004','PLOMB001','PLAT001']\n",
    "        catsRF5 = ['NO_PRINCIPALES','FOURNITURE','MO000','PEINT001','PEINT003','PEINT004','PEINT_AUTRE','PLOMB001','PLAT001','PLAT002']                             \n",
    "        rf4 = df[(~df['LABEL2'].str.contains('AUTRE'))&(~df['LABEL2'].str.contains('FOURNITURE'))&(~df['LABEL2'].str.contains('MO000'))].copy()\n",
    "        totalrf4 = rf4['TOTAL_RF4'].astype(float).sum()\n",
    "        if (len(rf4)>0)&(totalrf4 > 0):\n",
    "            #Se reparte el precio de Autre\n",
    "            rf4['PROP'] = rf4['TOTAL_RF4']/totalrf4\n",
    "            preu_a_repartir = float(df[(df['LABEL2'].str.contains('AUTRES'))|(df['LABEL2'].str.contains('PEINT_AUTRE'))]['TOTAL VALUE'].sum())\n",
    "            rf4['TOTAL_RF4'] = rf4['TOTAL_RF4'].astype(float) + preu_a_repartir*rf4['PROP'].astype(float)\n",
    "            #Para los que tienen unit price estimamos la cantidad\n",
    "            unit_price = rf4[(rf4['UNIT PRICE']!='nan')&(rf4['UNIT PRICE']!='')].copy()\n",
    "            unit_price['QTE EST'] = unit_price['TOTAL VALUE']/unit_price['UNIT PRICE'].astype(float)\n",
    "            unit_price['UNIT_PRIX_EST_RF4'] = unit_price['TOTAL_RF4']/unit_price['QTE EST'].astype(float)\n",
    "            #Para los que tienen cantidad estimamos unit price\n",
    "            qte = rf4[(rf4['QUANTITY2']!='nan')&(rf4['QUANTITY2']!='')].copy()\n",
    "            qte['UNIT_PRIX_QTE_RF4'] = qte['TOTAL_RF4'].astype(float)/qte['QUANTITY2'].astype(float)\n",
    "            qte['UNIT_PRIX_EST_RF5'] = qte['TOTAL VALUE'].astype(float)/qte['QUANTITY2'].astype(float)\n",
    "            df = pd.merge(df, unit_price[['ID DOC','PAGE','RECORD','UNIT_PRIX_EST_RF4']],on=['ID DOC','PAGE','RECORD'],how='left')\n",
    "            df['UNIT_PRIX_EST_RF4'] = df['UNIT_PRIX_EST_RF4'].fillna(0.0)\n",
    "            df = pd.merge(df, qte[['ID DOC','PAGE','RECORD','UNIT_PRIX_QTE_RF4','UNIT_PRIX_EST_RF5']],on=['ID DOC','PAGE','RECORD'],how='left')\n",
    "            df['UNIT_PRIX_QTE_RF4'] = df['UNIT_PRIX_QTE_RF4'].fillna(0.0)\n",
    "            for cat in catsRF5:\n",
    "                #Para cada categoria comprobamos los RF 4 y 5\n",
    "                df_aux = df[(df['LABEL2'].str.contains(cat))&(~df['QUANTITY2'].isin(values))&(df['F']==False)].copy()\n",
    "                if len(df_aux)>0:\n",
    "                    df_aux['UNIT PRICE'] = df_aux['UNIT PRICE'].astype(str)\n",
    "                    if cat in catsRF4:                                                                                                                                                                                                                                             \n",
    "                        df_2.at[0,'RF4_'+cat] = df_aux[(df_aux['UNIT_PRIX_QTE_RF4']>0)]['UNIT_PRIX_QTE_RF4'].mean()\n",
    "                        df_2.at[0,'RF4_'+cat+'_EST'] = df_aux[(df_aux['UNIT_PRIX_EST_RF4']>0)]['UNIT_PRIX_EST_RF4'].mean()\n",
    "                        df_2.at[0,'RF4_'+cat + '_ACTIVATE'] = df_aux[(df_aux['UNIT_PRIX_QTE_RF4']>0)]['UNIT_PRIX_QTE_RF4'].mean() < dic4[cat]\n",
    "                        df_2.at[0,'RF4_'+cat+'_EST_ACTIVATE'] = df_aux[(df_aux['UNIT_PRIX_EST_RF4']>0)]['UNIT_PRIX_EST_RF4'].mean() < dic4[cat]\n",
    "                        redflag4.append((df_2.at[0,'RF4_'+cat]>dic4[cat])+(df_2.at[0,'RF4_'+cat+'_EST']>dic4[cat]))\n",
    "                    df_2.at[0,'RF5_'+cat] = df_aux[(df_aux['UNIT PRICE']!='nan')&(df_aux['UNIT PRICE']!='')]['UNIT PRICE'].astype(float).mean()\n",
    "                    df_2.at[0,'RF5_'+cat+'_EST'] = df_aux[(df_aux['UNIT_PRIX_EST_RF5']>0)]['UNIT_PRIX_EST_RF5'].mean()\n",
    "                    df_2.at[0,'RF5_'+cat+ '_ACTIVATE'] = df_aux[(df_aux['UNIT PRICE']!='nan')&(df_aux['UNIT PRICE']!='')]['UNIT PRICE'].astype(float).mean() < dic5[cat]\n",
    "                    df_2.at[0,'RF5_'+cat+'_EST_ACTIVATE'] = df_aux[(df_aux['UNIT_PRIX_EST_RF5']>0)]['UNIT_PRIX_EST_RF5'].mean() < dic5[cat]\n",
    "                    if cat in cols_ref_prix:\n",
    "                        redflag5.append((df_2.at[0,'RF5_'+cat]>dic5[cat])+(df_2.at[0,'RF5_'+cat+'_EST']>dic5[cat]))\n",
    "                        \n",
    "    df_2 = df_2.fillna(0.0)\n",
    "\n",
    "    df_2.loc[df_2['RF2_NUMREG']==0,'RF2_QTE'] = 1\n",
    "    #Calculamos el booleano de cada RF\n",
    "    df_2.at[0,'RF1'] = (df_2.at[0,'RF1_DOC']>RF1_HT)\n",
    "    df_2.at[0,'RF2'] = ((3*df_2.at[0,'RF2_QT1'] + 2*df_2.at[0,'RF2_QTE'] + df_2.at[0,'RF2_UPE'] + df_2.at[0,'RF2_F']) > 2)\n",
    "    df_2.at[0,'RF3'] = (df_2.at[0,'RF3_AUT2']>RF3_AUT)\n",
    "    df_2.at[0,'RF4'] = any(redflag4)\n",
    "    df_2.at[0,'RF5'] = any(redflag5)\n",
    "\n",
    "    return df_2\n",
    "                                                                                                                                                 \n",
    "\n",
    "def returnQte(df):\n",
    "    #La cantidad del registro se busca en el campo Cantidad y si este es nan o 1 se busca en el texto si lo hay\n",
    "    values = ['1', '1.', '1.0', '1,', '1,0','1.00','1,00']\n",
    "    if (df['QUANTITY'] not in (values+['nan'])):\n",
    "        return df['QUANTITY']\n",
    "    if (df['TEXT QUANTITY VALUE'] != 'nan'):\n",
    "        return df['TEXT QUANTITY VALUE'] \n",
    "    return df['QUANTITY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d1e4ead09f484c91818f1f85bd4311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Générer les classes', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Javascript, display\n",
    "from ipywidgets import widgets\n",
    "\n",
    "def run_all(ev):\n",
    "    display(Javascript('IPython.notebook.execute_cells_above()'))\n",
    "\n",
    "button = widgets.Button(description=\"Générer les classes\")\n",
    "button.on_click(run_all)\n",
    "display(button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection à l'ICR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Générer un token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06102780db814d7ab4f6487ed18b2ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description=\"Générer un token de connection à l'ICR\", style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bbc72dc02cc47afbf048b2b258e39f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "button = widgets.Button(description=\"Générer un token de connection à l'ICR\")\n",
    "output = widgets.Output()\n",
    "\n",
    "display(button, output)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        #generation d'un token pour pouvoir accéder à l'API\n",
    "        param_token={'user':'billma_cofare','password':'cW0cXD_fJMATJWpq-hGWHfnsakySpQ_L','client':'multiasistencia'} # parametre\n",
    "        reponses_token=requests.post('https://multiasistencia.pervasive-tech.com/token/cofare/2.1',json=(param_token)) # requete\n",
    "        tok = reponses_token.json()['token'] # token utilisé pour accéder à l'API\n",
    "        print(\"token :\" + tok)\n",
    "\n",
    "button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9d563d5b4dc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#generation d'un token pour pouvoir accéder à l'API (ne doit s'éxecuter que si beoin de changement du token et pas a chaque demande)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mparam_token\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'user'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'billma_cofare'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'password'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'cW0cXD_fJMATJWpq-hGWHfnsakySpQ_L'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'client'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'multiasistencia'\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;31m# parametre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mreponses_token\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://multiasistencia.pervasive-tech.com/token/cofare/2.1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_token\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# requete\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreponses_token\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'token'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# token utilisé pour accéder à l'API\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#token=\"DhwZETmhED0xzBfqfMeN7Q\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "# identifiants pour l'accès au S3\n",
    "ACCESS_KEY_ID = 'AKIAJUWSKSHW6B4ZSK7Q'\n",
    "ACCESS_SECRET_KEY = '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'\n",
    "BUCKET_NAME = 'billma-s3'\n",
    "\n",
    "#generation d'un token pour pouvoir accéder à l'API (ne doit s'éxecuter que si beoin de changement du token et pas a chaque demande)\n",
    "param_token={'user':'billma_cofare','password':'cW0cXD_fJMATJWpq-hGWHfnsakySpQ_L','client':'multiasistencia'} # parametre\n",
    "#reponses_token=requests.post('https://multiasistencia.pervasive-tech.com/token/cofare/2.1',json=(param_token)) # requete\n",
    "#token=reponses_token.json()['token'] # token utilisé pour accéder à l'API\n",
    "token = tok\n",
    "\n",
    "\n",
    "# créer workbook & worksheet pour partidas\n",
    "wb_prediction_partidas = Workbook()\n",
    "ws_prediction_partidas = wb_prediction_partidas.active\n",
    "\n",
    "# créer workbook & worksheet pour red flags\n",
    "wb = Workbook()\n",
    "ws_red_flags = wb.active\n",
    "\n",
    "ligne_data=0\n",
    "z=0   #compteur pour compter l'id du fichier en cours de traitement\n",
    "pathname=os.path.abspath(r\"C:\\Users\\gsegonds\\Desktop\\topdf\")  # chemin d'accès de mon dossier avec dedans mes sous dossiers\n",
    "\n",
    "for path, dirs, files in os.walk(pathname):\n",
    "    path=path\n",
    "    for filename in files: # parcours les sous\n",
    "        if (filename.endswith(\".pdf\") or filename.endswith(\".PDF\") or filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".JPG\") or filename.endswith(\".JPEG\") or filename.endswith(\".png\") or filename.endswith(\".PNG\") or filename.endswith(\".tif\") or filename.endswith(\".TIF\")): # si mon fichier est un pdf\n",
    "            if filename.endswith(\".tif\") or filename.endswith(\".TIF\"):\n",
    "                base_filename = os.path.basename(filename)\n",
    "                output_file = path + '\\\\' + filename + \"_tmp_.pdf\"\n",
    "                try:\n",
    "                    with open(output_file,\"wb\") as f:\n",
    "                        f.write(img2pdf.convert( path + '/' + filename))\n",
    "                except:\n",
    "                    1\n",
    "            if filename.endswith(\".png\") or filename.endswith(\".jpeg\") or filename.endswith(\".jpg\") or filename.endswith(\".JPG\"):\n",
    "                PNG_FILE = pathname + \"\\\\\" + filename\n",
    "                output_file = pathname +  \"\\\\\" + filename.replace(' ','') + '.pdf'\n",
    "                rgba = Image.open(PNG_FILE)\n",
    "                rgb = Image.new('RGB', rgba.size, (255, 255, 255))  # white background\n",
    "                rgb.paste(rgba, mask=rgba.split()[2])               # paste using alpha channel as mask\n",
    "                rgb.save(output_file, 'PDF', resoultion=100.0)\n",
    "            if filename.endswith(\".pdf\") or filename.endswith(\".PDF\"):\n",
    "                output_file = filename\n",
    "            \n",
    "            print(\"Inicio tratamiento: \" + filename)\n",
    "            path_upload_amazon=os.path.join(path, output_file) # chemin d'accès local de mon fichier\n",
    "            \n",
    "            #établir connexion avec le S3\n",
    "            s3= boto3.resource('s3',aws_access_key_id=ACCESS_KEY_ID,aws_secret_access_key=ACCESS_SECRET_KEY,) \n",
    "            \n",
    "            #upload fichiers sur le S3\n",
    "            data = open(path_upload_amazon, 'rb')\n",
    "            s3.Bucket(BUCKET_NAME).put_object(Key=os.path.basename(path_upload_amazon), Body=data) # key est le nom visible sur le S3                                  \n",
    "            \n",
    "            # génération d'une URL signée (temporaire) pour pouvoir accéder à l'API\n",
    "            s3_url = boto3.client('s3',aws_access_key_id=ACCESS_KEY_ID,aws_secret_access_key=ACCESS_SECRET_KEY)\n",
    "            url_signed=s3_url.generate_presigned_url('get_object',Params={'Bucket':BUCKET_NAME,'Key':os.path.basename(path_upload_amazon)},ExpiresIn=3600)\n",
    "            \n",
    "            \n",
    "            # arguments API\n",
    "            meta={'tipo_bucket':'URL','user':'billma_cofare','password':'cW0cXD_fJMATJWpq-hGWHfnsakySpQ_L','object_storage':'Bucket','carpeta':''}\n",
    "            json_params={'url':url_signed,'meta':meta,'model': 'cofare','action':'predict','user':'billma_cofare','token':token}\n",
    "            # requete API\n",
    "            reponses=requests.post('https://multiasistencia.pervasive-tech.com/models/cofare/2.1/online/',json=json_params)            \n",
    "            \n",
    "            print(reponses.status_code)\n",
    "            \n",
    "            if(reponses.status_code == 200):\n",
    "                                \n",
    "                try:\n",
    "                    json_string=json.dumps(reponses.json())\n",
    "                    result = welcome_from_dict(json.loads(json_string)) # creation d'un objet7\n",
    "\n",
    "                    liste_data=[]\n",
    "                    ligne_data=0 # ligne de tout mon pdf \n",
    "\n",
    "\n",
    "                    # creation de 2 dataframes qui ont des valeurs fixe par pdf (ID, elapsed, nbr de page) préremplis avec des valeur par défauts\n",
    "                    df_first_layer_fixe= pd.DataFrame(data={\"FileID\":2,\"Elapsed\":1},index=[0])\n",
    "                    df_second_layer_fixe=pd.DataFrame(data={\"Nombre_Pages\":6},index=[0])\n",
    "\n",
    "\n",
    "                    frames=[] # liste contenant mes dataframes qui ont des valeurs fixe par page (SIRET, EMITER, BODY, RECIPIENT, TOTAL, TOTAL AUX, PAGES, TYPE, )\n",
    "                    frame_interne=[] # liste contenant les dataframe de ma page en cour\n",
    "\n",
    "\n",
    "\n",
    "                    #on boucle sur les pages du pdf:\n",
    "                    for indice_page_document,page in enumerate(result.output.pages):\n",
    "\n",
    "                        # creation de 8 dataframes qui ont des valeurs fixe par page (EMITER, RECIPIENT, SIRET, TOTAL, TOTAL AUX, PAGES(en cours), Type, BODY(contient nbr de lignes)) préremplis avec des valeur par défauts\n",
    "                        df_layer_emiter=pd.DataFrame(data={\"emiter\": 1,\"SCORE EMITER\":2,\"SCORE EMITER OCR\":3,\"xmaxEmiter\":4,\"xminEmiter\":5,\"ymaxEmiter\":6,\"yminEmiter\":7},index=[0]) # on fait varier la page et la bloc reconocido\n",
    "                        df_layer_recipient=pd.DataFrame(data={\"recipient\": 1,\"SCORE RECIPIENT\":2,\"SCORE RECIPIENT OCR\":3,\"xmaxRecipient\":4,\"xminRecipient\":5,\"ymaxRecipient\":6,\"yminRecipient\":7},index=[0]) # on fait varier la page et la bloc reconocido\n",
    "                        df_layer_siret=pd.DataFrame(data={\"SIRET\": 1,\"SCORE SIRET\":2,\"SCORE SIRET OCR\":3,\"xmaxSiret\":4,\"xminSiret\":5,\"ymaxSiret\":6,\"yminSiret\":7},index=[0]) # on fait varier la page et la bloc reconocido\n",
    "                        df_layer_total=pd.DataFrame(data={\"TOTAL\": 1,\"SCORE TOTAL\":2,\"SCORE TOTAL OCR\":3,\"xmaxTotal\":4,\"xminTotal\":5,\"ymaxTotal\":6,\"yminTotal\":7},index=[0]) # on fait varier la page et la bloc reconocido\n",
    "                        df_layer_total_aux=pd.DataFrame(data={\"TOTAL con impuestos incluidos o no especificado\": 1,\"SCORE TOTAL AUX\":2,\"SCORE TOTAL AUX OCR\":3,\"xmaxTotalAUX\":4,\"xminTotalAUX\":5,\"ymaxTotalAUX\":6,\"yminTotalAUX\":7},index=[0]) # on fait varier la page et la bloc reconocido\n",
    "                        df_layer_3=pd.DataFrame(data={\"PAGES\":7},index=[0]) # fixe\n",
    "                        df_layer_4=pd.DataFrame(data={\"Type\":78,\"SCORE Type\":5},index=[0]) # fixe\n",
    "                        df_layer_8_variable_body=pd.DataFrame(data={\"RECORD\":1,\"SCORE BODY\":2,\"SCORE TOTAL BODY\":3,\"XMAXBODY\":4,\"XMINBODY\":5,\"YMAXBODY\":6,\"YMINBODY\":7},index=[0]) # on fait varier la page et la bloc reconocido\n",
    "\n",
    "\n",
    "                        # boucle sur bloques reconocidos \n",
    "                        for indice_Bloques_reconocidos,page in enumerate(result.output.pages[0].bbox):\n",
    "                            if(indice_Bloques_reconocidos==0): # acces au body qui contient les lignes de ma page\n",
    "\n",
    "                                # creation de 5 dataframes qui ont des valeurs fixe par ligne de body (quantite etc. , coordonnees lignes, nom et score des categories MA, aggregated category, indice ligne en cours) préremplis avec des valeur par défauts\n",
    "                                df_layer_12_1 = pd.DataFrame(data= {'QUANTITE':1,'QUANTITE SCORE':2,'TEXT RECORD':3,'TEXT RECORD SCORE':4,'TEXT QUANTITY':5,'TEXT QUANTITY SCORE':6,'TEXT UNITS':7,'TEXT UNITS SCORE':8,'TOTAL VALUE':9,'TOTAL VALUE SCORE':10,'UNITS PRICE':11,'UNITS PRICE SCORE':12,'UNITS PRICE TEXT':13,'UNITS PRICE TEXT SCORE':14,'UNITS':15,'UNITS SCORE':16},index=[0])\n",
    "                                df_layer_12_2=pd.DataFrame(data={\"H_X0\":1,\"H_X1\":2,\"H_Y0\":3,\"H_Y1\":4,\"N_CATEGORIES_BAREMO\":5},index=[0])\n",
    "                                df_layer_12_3=pd.DataFrame(data={\"CATEGORIE MA 1\":1,\"SCORE CATEGORIE MA 1\":2,\"CATEGORIE MA 2\":3,\"SCORE CATEGORIE MA 2\":4,\"CATEGORIE MA 3\":5,\"SCORE CATEGORIE MA 3\":6,\"CATEGORIE MA 4\":7,\"SCORE CATEGORIE MA 4\":8,\"CATEGORIE MA 5\":9,\"SCORE CATEGORIE MA 5\":10,\"CATEGORIE MA 6\":11,\"SCORE CATEGORIE MA 6\":12,\"CATEGORIE MA 7\":13,\"SCORE CATEGORIE MA 7\":14,\"CATEGORIE MA 8\":15,\"SCORE CATEGORIE MA 8\":1,\"CATEGORIE MA 9\":2,\"SCORE CATEGORIE MA 9\":3,\"CATEGORIE MA 10\":4,\"SCORE CATEGORIE MA 10\":5,\"CATEGORIE MA 11\":6,\"SCORE CATEGORIE MA 11\":7,\"CATEGORIE MA 12\":8,\"SCORE CATEGORIE MA 12\":9,\"CATEGORIE MA 13\":10,\"SCORE CATEGORIE MA 13\":11,\"CATEGORIE MA 14\":12,\"SCORE CATEGORIE MA 14\":13,\"CATEGORIE MA 15\":14,\"SCORE CATEGORIE MA 15\":15},index=[0])\n",
    "                                df_layer_12_4=pd.DataFrame(data={\"AGGREGATED CATEGORY\":1,\"REFERENCE PRICE\":2},index=[0])\n",
    "                                df_layer_11_variable_record=pd.DataFrame(data={\"Record\":1},index=[0])\n",
    "\n",
    "                                # si la liste contenant les lignes est vide alors toutes les valeurs sont \"nan\"\n",
    "                                if not result.output.pages[indice_page_document].bbox[0].content.records:\n",
    "                                    ligne_body=1\n",
    "\n",
    "                                    serie_layer_12_1=pd.Series(data=['nan']*len(df_layer_12_1.columns),index=df_layer_12_1.columns)# creation de la ligne avec nan\n",
    "                                    df_layer_12_1=df_layer_12_1.append(serie_layer_12_1, ignore_index=True) # ajout ligne au dataframe\n",
    "\n",
    "                                    serie_layer_12_2=pd.Series(data=['nan']*len(df_layer_12_2.columns),index=df_layer_12_2.columns)\n",
    "                                    df_layer_12_2=df_layer_12_2.append(serie_layer_12_2,ignore_index=True)  \n",
    "\n",
    "                                    serie_layer_12_3=pd.Series(data=['nan']*len(df_layer_12_3.columns),index=df_layer_12_3.columns)\n",
    "                                    df_layer_12_3=df_layer_12_3.append(serie_layer_12_3,ignore_index=True)\n",
    "\n",
    "                                    serie_layer_12_4=pd.Series(data=['nan']*len(df_layer_12_4.columns),index=df_layer_12_4.columns)\n",
    "                                    df_layer_12_4=df_layer_12_4.append(serie_layer_12_4,ignore_index=True)\n",
    "\n",
    "                                    df_layer_11_variable_record=df_layer_11_variable_record.append(pd.Series(data=[\"nan\"],index=df_layer_11_variable_record.columns),ignore_index=True)\n",
    "\n",
    "\n",
    "                                # si cette liste est non vide\n",
    "                                else:\n",
    "                                    ligne_body=result.output.pages[indice_page_document].bbox[0].content.n_records #  nombre de ligne total de mon document\n",
    "\n",
    "\n",
    "                                    # parcourt cette liste (donc parcout des lignes du doc en cours et de la page en cours)\n",
    "                                    for indice_ligne_body,content in enumerate(result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records): \n",
    "\n",
    "                                        liste_data.append(indice_ligne_body)\n",
    "\n",
    "                                        #creation ligne contenant  les informations de la ligne en cours (quantite etc. , nom et score des categories MA, aggregated category,)\n",
    "                                        serie_layer_12_1=pd.Series(data=[result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].quantite.content,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].quantite.score,\n",
    "                                                                        result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].text.content,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].text.score,\n",
    "                                                                        result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].text_quantite.content,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].text_quantite.score,\n",
    "                                                                    result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].text_units.content,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].text_units.score,\n",
    "                                                                      result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].total_prix.content,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].total_prix.score,\n",
    "                                                                   result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].unit_prix.content,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].unit_prix.score,\n",
    "                                                                        result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].unit_prix_text.content,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].unit_prix_text.score,\n",
    "                                                                    result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].units.content,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].units.score,\n",
    "                                                                        ],index=df_layer_12_1.columns)\n",
    "\n",
    "                                        #ajout au dataframe\n",
    "                                        df_layer_12_1=df_layer_12_1.append(serie_layer_12_1,ignore_index=True)\n",
    "\n",
    "                                        # meme chose avec  coordonnees ligne en cours + n categories bareme\n",
    "                                        serie_layer_12_2=pd.Series(data=[result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].h_x0,\n",
    "                                                                        result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].h_x1,\n",
    "                                                                        result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].h_y0,\n",
    "                                                                        result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].h_y1,\n",
    "                                                                       result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].n_categories_baremo],\n",
    "                                                                   index=df_layer_12_2.columns)\n",
    "                                        df_layer_12_2=df_layer_12_2.append(serie_layer_12_2,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "                                        #creation ligne contenant  indice de la ligne en cours\n",
    "                                        serie_layer_11_variable=pd.Series(data=indice_ligne_body,index=df_layer_11_variable_record.columns)\n",
    "                                        #ajout dataframe\n",
    "                                        df_layer_11_variable_record=df_layer_11_variable_record.append(serie_layer_11_variable,ignore_index=True)\n",
    "\n",
    "\n",
    "                                        # parcours la liste \"agg_cat\" qui contient le nom et le score de chaque catégories aggrégé \n",
    "                                        for indice_ligne_agg_cat,content in enumerate(result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].agg_cat):\n",
    "                                            serie_layer_12_4=pd.Series(data=[result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].agg_cat[indice_ligne_agg_cat].cat,\n",
    "                                                                             result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].agg_cat[indice_ligne_agg_cat].reference_price],index=df_layer_12_4.columns)\n",
    "                                            df_layer_12_4=df_layer_12_4.append(serie_layer_12_4,ignore_index=True) \n",
    "\n",
    "\n",
    "                                        liste_categories=[] # liste qui va contenir nom et score de chaque catégorie MA\n",
    "                                        #boucle sur la liste \"categories\" qui contient le nom et le score de chaque catégorie MA (15) -> \n",
    "                                        for indice_ligne_categories_ma,content in enumerate(result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].categories):\n",
    "                                            liste_categories.append(result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].categories[indice_ligne_categories_ma].cat)\n",
    "                                            liste_categories.append(result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content.records[indice_ligne_body].categories[indice_ligne_categories_ma].score)\n",
    "\n",
    "                                        # création série qui contient nom et score de chaque catégorie MA pour la ligne en cours\n",
    "                                        serie_layer_12_3=pd.Series(data=liste_categories,index=df_layer_12_3.columns)\n",
    "                                        #ajout dataframe\n",
    "                                        df_layer_12_3=df_layer_12_3.append(serie_layer_12_3,ignore_index=True)            \n",
    "\n",
    "                            # création des lignes avec des valeurs fixe par pages (EMITTER, RECIPIENT, SIRET, TOTAL, TOTAL AUX )\n",
    "                            if(indice_Bloques_reconocidos==1):\n",
    "                                #creation ligne contenant EMITER de la page en cours\n",
    "                                serie_layer_emiter=pd.Series(data=[result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].score,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].scoreocr,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].position.xmax,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].position.xmin,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].position.ymax,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].position.ymin],index=df_layer_emiter.columns) # on fait varier la page et la bloc reconocido)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
    "                            if(indice_Bloques_reconocidos==2):\n",
    "                                #creation ligne contenant RECIPIENT de la page en cours\n",
    "                                serie_layer_recipient=pd.Series(data=[result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].score,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].scoreocr,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].position.xmax,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].position.xmin,result.output.pages[0].bbox[indice_Bloques_reconocidos].position.ymax,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].position.ymin],index=df_layer_recipient.columns)\n",
    "                            if(indice_Bloques_reconocidos==3):\n",
    "                                #creation ligne contenant le SIRET de la page en cours\n",
    "                                serie_layer_siret=pd.Series(data=[result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].score,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].scoreocr,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].position.xmax,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].position.xmin,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].position.ymax,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].position.ymin],index=df_layer_siret.columns) # on fait varier la page et la bloc reconocido                \n",
    "                            if(indice_Bloques_reconocidos==4):\n",
    "                                #creation ligne contenant le total de la page en cours\n",
    "                                serie_layer_total=pd.Series(data=[result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].score,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].scoreocr,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].position.xmax,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].position.xmin,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].position.ymax,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].position.ymin],index=df_layer_total.columns) # on fait varier la page et la bloc reconocido)\n",
    "                            if(indice_Bloques_reconocidos==5):\n",
    "                                #creation ligne contenant le total aux de la page en cours\n",
    "                                serie_layer_total_aux=pd.Series(data=[result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].content,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].score,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].scoreocr,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].position.xmax,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].position.xmin,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].position.ymax,result.output.pages[indice_page_document].bbox[indice_Bloques_reconocidos].position.ymin],index=df_layer_total_aux.columns)\n",
    "                            #else:\n",
    "                                #print(\"ok\")\n",
    "\n",
    "                        # AJOUT DES VALEURS FIXES PAR PAGE A LEUR DATAFRAME RESPECTIVE\n",
    "\n",
    "                        # creation et ajout dataframe de la page en cours\n",
    "                        serie_layer_3=pd.Series(data=[result.output.pages[indice_page_document].page],index=df_layer_3.columns)\n",
    "                        df_layer_3=df_layer_3.append(serie_layer_3,ignore_index=True)\n",
    "\n",
    "                        #ajout dataframe (EMITTER, RECIPIENT, SIRET, TOTAL, TOTAL AUX ) + BODY\n",
    "                        df_layer_emiter=df_layer_emiter.append(serie_layer_emiter,ignore_index=True)\n",
    "                        df_layer_recipient=df_layer_recipient.append(serie_layer_recipient,ignore_index=True)\n",
    "                        df_layer_siret=df_layer_siret.append(serie_layer_siret,ignore_index=True)\n",
    "                        df_layer_total=df_layer_total.append(serie_layer_total,ignore_index=True)\n",
    "                        df_layer_total_aux=df_layer_total_aux.append(serie_layer_total_aux,ignore_index=True)\n",
    "\n",
    "                        #creation et ajout dataframe de BODY\n",
    "                        serie_layer_8_variable = pd.Series(data=[result.output.pages[indice_page_document].bbox[0].content.n_records, result.output.pages[indice_page_document].bbox[0].score,result.output.pages[indice_page_document].bbox[0].scoreocr,result.output.pages[indice_page_document].bbox[0].position.xmax,result.output.pages[indice_page_document].bbox[0].position.xmin,result.output.pages[indice_page_document].bbox[0].position.ymax,result.output.pages[indice_page_document].bbox[0].position.ymin],index=df_layer_8_variable_body.columns) # on fait varier la page et la bloc reconocidoand\n",
    "                        df_layer_8_variable_body= df_layer_8_variable_body.append(serie_layer_8_variable,ignore_index=True)\n",
    "\n",
    "                        # creation et ajout dataframe  du  type et de la probability de la page en cours\n",
    "                        serie_layer_4_fixe=pd.Series(data=[result.output.pages[indice_page_document].type,result.output.pages[indice_page_document].probability], index=df_layer_4.columns)\n",
    "                        df_layer_4=df_layer_4.append(serie_layer_4_fixe,ignore_index=True)                   \n",
    "\n",
    "                        # fusion des différents informations concernant la ligne en cours (quantite etc. , coordonnees lignes, nom et score des categories MA, aggregated category, indice ligne en cours) préremplis avec des valeur par défaut)\n",
    "                        df_page_variable = pd.concat([df_layer_11_variable_record,df_layer_12_1,df_layer_12_2,df_layer_12_3,df_layer_12_4], axis=1)\n",
    "                        df_page_variable =df_page_variable.drop([0],axis=0) # supprime valeurs par défauts\n",
    "                        df_page_variable =df_page_variable.reset_index() # reset index des lignes\n",
    "\n",
    "                        #ajout du dataframe contenant les informations de la liste en cours dans la liste frame_interne ( qui contient les dataframes de chaque ligne )\n",
    "                        frame_interne.append(df_page_variable)   \n",
    "\n",
    "                        ligne_data=ligne_data+ligne_body\n",
    "\n",
    "                        #concatenation horizontale des dataframes contenant des valeurs fixe par page (EMITER, RECIPIENT, SIRET, TOTAL, TOTAL AUX, PAGES(en cours), Type, BODY(contient nbr de lignes))\n",
    "                        df_layer_fixe_page=pd.concat([df_layer_3,df_layer_4,df_layer_8_variable_body,df_layer_total,df_layer_total_aux,df_layer_siret,df_layer_recipient,df_layer_emiter],axis=1, join='inner') \n",
    "                        df_layer_fixe_page=df_layer_fixe_page.drop([0],axis=0) # suppresion valeurs par défauts\n",
    "                        df_layer_fixe_page=df_layer_fixe_page.reset_index() # réindexation\n",
    "\n",
    "                        # création du même dataframe avec un nombre de ligne dupliqués (ligne_body qui est égale un nombre de ligne de ma page en cours)\n",
    "                        df_layer_fixe_page_duplicate=df_layer_fixe_page.loc[np.repeat(df_layer_fixe_page.index.values, ligne_body)] # dupliquer ligne d'un dataframe de la page en question\n",
    "                        df_layer_total_duplicate = df_layer_fixe_page.loc[np.repeat(df_layer_fixe_page.index.values, ligne_body)] \n",
    "                        df_layer_total_duplicate =df_layer_total_duplicate.reset_index()\n",
    "                        #ajout dans la liste frames, le data frame avec le bon nombre de ligne du dataframe avec les informations fixe de la page en cours\n",
    "                        frames.append(df_layer_total_duplicate) \n",
    "\n",
    "                    # concatenation verticale des dataframes de chaque page (avec les informations fixe par ligne du body)\n",
    "                    df_page_variable_concat_duplicate=pd.concat(frame_interne)\n",
    "                    df_page_variable_concat_duplicate= df_page_variable_concat_duplicate.reset_index()\n",
    "\n",
    "\n",
    "                    #concatenation verticale des dataframes de chaque page (contenant les informations fixe de la page (EMITER, RECIPIENT, SIRET, TOTAL, TOTAL AUX, PAGES(en cours), Type, BODY(contient nbr de lignes))\n",
    "                    df_layer_total_duplicate_concat=pd.concat(frames)\n",
    "                    del df_layer_total_duplicate_concat['level_0']\n",
    "                    del df_layer_total_duplicate_concat['index']\n",
    "                    df_layer_total_duplicate_concat=df_layer_total_duplicate_concat.reset_index() # réindexation\n",
    "\n",
    "                    # creation dataframe avec les valeurs fixe par pdf ( ID, nombre de page et elapsed )\n",
    "\n",
    "                    #filed id + elapsed\n",
    "                    serie_first_layer_fixe=pd.Series(data=[result.fileid,result.elapsed],index=df_first_layer_fixe.columns)\n",
    "                    df_first_layer_fixe=df_first_layer_fixe.append(serie_first_layer_fixe,ignore_index=True)\n",
    "                    df_first_layer_fixe=df_first_layer_fixe.drop([0],axis=0)\n",
    "                    df_first_layer_fixe=df_first_layer_fixe.reset_index()\n",
    "\n",
    "                    #nombre de page\n",
    "                    df_second_layer_fixe=df_second_layer_fixe.append(pd.Series(data=[result.output.n_pages],index=df_second_layer_fixe.columns),ignore_index=True)\n",
    "                    df_second_layer_fixe=df_second_layer_fixe.drop([0],axis=0)\n",
    "                    df_second_layer_fixe=df_second_layer_fixe.reset_index()\n",
    "\n",
    "                    # concatenation des 2 dataframes\n",
    "                    df_first_second_layer_fixe=pd.concat([df_first_layer_fixe,df_second_layer_fixe],axis=1)\n",
    "\n",
    "                    #repete le dataframe, avec le nombre de ligne du pdf\n",
    "                    df_first_second_layer_fixe = df_first_second_layer_fixe.loc[np.repeat(df_first_second_layer_fixe.index.values, ligne_data)] # dupliquer ligne d'un dataframe\n",
    "                    df_first_second_layer_fixe=df_first_second_layer_fixe.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "                    # DATAFRAME FINAL CONTIENT \n",
    "                    # dataframe avec valeur fixe par pdf : df_first_second_layer_fixe\n",
    "                    # dataframe avec valeurs fixes par page :\n",
    "                    # dataframe avec valeur fixes par lignes :\n",
    "                    fusion = pd.concat([df_first_second_layer_fixe,df_layer_total_duplicate_concat,df_page_variable_concat_duplicate],axis=1)\n",
    "\n",
    "\n",
    "                    # suppression de 2 colonnes créer suite à la réindexation\n",
    "                    del fusion['index'] \n",
    "                    del fusion['level_0']\n",
    "                    \n",
    "                    fusion1 = fusion[['FileID', 'PAGES', 'Type', 'SCORE Type', 'TOTAL', 'SCORE TOTAL', 'SCORE TOTAL OCR','xminTotal','xmaxTotal','yminTotal','ymaxTotal','FileID','SCORE BODY', 'SCORE TOTAL BODY', 'XMINBODY', 'XMAXBODY', 'YMINBODY', 'YMAXBODY','SIRET', 'SCORE SIRET', 'SCORE SIRET OCR', 'xminSiret', 'xmaxSiret', 'yminSiret', 'ymaxSiret', 'recipient', 'SCORE RECIPIENT', 'SCORE RECIPIENT OCR', 'xminRecipient', 'xmaxRecipient', 'yminRecipient', 'ymaxRecipient', 'emiter', 'SCORE EMITER', 'SCORE EMITER OCR', 'xminEmiter', 'xmaxEmiter', 'yminEmiter', 'ymaxEmiter', 'RECORD', 'Record', 'TEXT RECORD', 'TEXT RECORD SCORE', 'UNITS', 'UNITS SCORE', 'QUANTITE', 'QUANTITE SCORE', 'UNITS PRICE', 'UNITS PRICE SCORE', 'TOTAL VALUE', 'TOTAL VALUE SCORE', 'QUANTITE', 'QUANTITE SCORE', 'TEXT UNITS', 'TEXT UNITS SCORE', 'UNITS PRICE', 'UNITS PRICE SCORE', \"H_X0\",\"H_Y0\",\"H_X1\",\"H_Y1\", 'N_CATEGORIES_BAREMO', \"CATEGORIE MA 1\",\"SCORE CATEGORIE MA 1\",\"CATEGORIE MA 2\",\"SCORE CATEGORIE MA 2\",\"CATEGORIE MA 3\",\"SCORE CATEGORIE MA 3\",\"CATEGORIE MA 4\",\"SCORE CATEGORIE MA 4\",\"CATEGORIE MA 5\",\"SCORE CATEGORIE MA 5\",\"CATEGORIE MA 6\",\"SCORE CATEGORIE MA 6\",\"CATEGORIE MA 7\",\"SCORE CATEGORIE MA 7\",\"CATEGORIE MA 8\",\"SCORE CATEGORIE MA 8\",\"CATEGORIE MA 9\",\"SCORE CATEGORIE MA 9\", 'AGGREGATED CATEGORY', 'REFERENCE PRICE']].copy()\n",
    "                    \n",
    "\n",
    "                    # TRAITEMENT RED FLAGS\n",
    "                    \n",
    "                    d = json.loads(json_string)\n",
    "                    partidas = get_pandas_out_of_json(d)\n",
    "                    rf = red_flags(partidas,a)\n",
    "                    del rf['RF2_SCORE']\n",
    "    \n",
    "                    # ecriture dans un excel\n",
    "                    # s'il s'agit du premier pdf \n",
    "                    if(z==0): \n",
    "\n",
    "                        #partidas \n",
    "                        # on écrit le nom des colonnes du dataframe sans l'index\n",
    "                        for r in dataframe_to_rows(fusion1, index=False, header=True): \n",
    "                            ws_prediction_partidas.append(r)\n",
    "\n",
    "\n",
    "                        #red flags\n",
    "                        # on écrit le nom des colonnes du dataframe sans l'index\n",
    "                        for p in dataframe_to_rows(rf, index=False, header=True): \n",
    "                            ws_red_flags.append(p)\n",
    "\n",
    "                    # sinon      \n",
    "                    else:\n",
    "\n",
    "                        #partidas\n",
    "                        # on itere sur les lignes sans réecrire le nom des colonnes\n",
    "                        for index, row in fusion1.iterrows(): \n",
    "                            ws_prediction_partidas.append(row.tolist())\n",
    "\n",
    "                        #redflags\n",
    "                        # on itere sur les lignes sans réecrire le nom des colonnes\n",
    "                        for index, row in rf.iterrows():  \n",
    "                            ws_red_flags.append(row.tolist())\n",
    "\n",
    "                    z=z+1 # incrémente l'index du pdf en cours\n",
    "\n",
    "\n",
    "                    #on supprime le pdf du S3\n",
    "                    obj_delete = s3.Object(BUCKET_NAME,os.path.basename(path_upload_amazon))\n",
    "                    obj_delete.delete()\n",
    "                    print(\"Fichero tratado y borrado: \"+ filename)\n",
    "                    # enregiste en local les .xlsx           \n",
    "                    wb_prediction_partidas.save(\"Partidas_parcial.xlsx\")\n",
    "                    wb.save(\"Red_flags_parcial.xlsx\")\n",
    "                except AssertionError:\n",
    "                    print(\"Error de formato de JSON\")\n",
    "                    file = open('unitaire','a') \n",
    "                    file.write(os.path.basename(path_upload_amazon)+'\\n')\n",
    "                    file.close()\n",
    "                    #on supprime le pdf du S3\n",
    "                    obj_delete = s3.Object(BUCKET_NAME,os.path.basename(path_upload_amazon))\n",
    "                    obj_delete.delete()\n",
    "                    print(\"Fichero NO tratado y borrado: \"+ filename)\n",
    "                except:\n",
    "                    print(\"Error de acceso al servicio\")\n",
    "                    file = open('unitaire','a') \n",
    "                    file.write(os.path.basename(path_upload_amazon)+'\\n')\n",
    "                    file.close()\n",
    "                    #on supprime le pdf du S3\n",
    "                    obj_delete = s3.Object(BUCKET_NAME,os.path.basename(path_upload_amazon))\n",
    "                    obj_delete.delete()\n",
    "                    print(\"Fichero NO tratado y borrado: \"+ filename)\n",
    "\n",
    "                \n",
    "            else: # on ecrit dans un .txt les fichiers qui n'ont pas été traités\n",
    "                file = open('unitaire','a') \n",
    "                file.write(os.path.basename(path_upload_amazon)+'\\n')\n",
    "                file.close()\n",
    "                #on supprime le pdf du S3\n",
    "                obj_delete = s3.Object(BUCKET_NAME,os.path.basename(path_upload_amazon))\n",
    "                obj_delete.delete()\n",
    "                print(\"Fichero NO tratado y borrado: \"+ filename)\n",
    "                \n",
    "for path, dirs, files in os.walk(pathname):\n",
    "    path=path\n",
    "    for filename in files: \n",
    "        if \"_tmp_\" in str(filename):\n",
    "            os.remove(path +'\\\\' + filename)\n",
    "\n",
    "\n",
    "       \n",
    "# enregiste en local les .xlsx \n",
    "wb_prediction_partidas.save(\"Partidas.xlsx\")\n",
    "wb.save(\"Red_flags.xlsx\")\n",
    "print(\"Final del tratamiento\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
